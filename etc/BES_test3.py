from langgraph.graph import StateGraph, END
import chromadb
from langchain.llms.base import LLM
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.prompts import PromptTemplate
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from typing import List, Dict, Any, Optional, Tuple, TypedDict, Annotated
import json
import requests
import warnings
import datetime
import os
import re
import operator
import chainlit as cl

# FutureWarning ë¬´ì‹œ
warnings.filterwarnings("ignore", category=FutureWarning)

class LMStudioLLM(LLM):
    """LM Studioì™€ ì—°ë™í•˜ëŠ” LangChain í˜¸í™˜ LLM í´ë˜ìŠ¤"""
    
    base_url: str = "http://127.0.0.1:1234/v1"
    model_name: str = "qwen/qwen3-coder-30b"
    temperature: float = 0.1
    max_tokens: int = 70000  # ìë™í™” ì½”ë“œ ìƒì„±ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
    
    def __init__(self, 
                 base_url: str = "http://127.0.0.1:1234/v1",
                 model_name: str = "qwen/qwen3-coder-30b",
                 temperature: float = 0.1,
                 max_tokens: int = 70000,
                 **kwargs):
        super().__init__(**kwargs)
        self.base_url = base_url.rstrip('/')
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self._test_connection()
    
    def _test_connection(self):
        """LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(f"{self.base_url}/models", timeout=5)
            if response.status_code == 200:
                models = response.json()
                print(f"âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models.get('data', []))}ê°œ")
            else:
                print(f"âš ï¸ LM Studio ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”: {response.status_code}")
        except Exception as e:
            print(f"âŒ LM Studio ì—°ê²° ì‹¤íŒ¨: {e}")
    
    @property
    def _llm_type(self) -> str:
        return "lm_studio"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        try:
            payload = {
                "model": self.model_name,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "stream": False
            }

            if stop:
                payload["stop"] = stop

            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=10000000  # 1000ì´ˆ (16ë¶„ 40ì´ˆ)ë¡œ ì„¤ì •
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                return f"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})"

        except Exception as e:
            return f"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}"

    async def ainvoke_with_history(self, messages: List[Dict[str, str]]) -> str:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•˜ì—¬ LM Studioì— ìš”ì²­
        messages: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]
        """
        try:
            payload = {
                "model": self.model_name,
                "messages": messages,  # âœ¨ ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "stream": False
            }

            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=10000000
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                return f"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})"

        except Exception as e:
            return f"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}"

class RAG_Pipeline :
    """
    Vector DB, Embedding Model, LM Studioë¥¼ ì—°ê²°í•˜ì—¬ RAGë¥¼ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤.
    """

    # âœ¨ í´ë˜ìŠ¤ ë³€ìˆ˜: í”„ë¡œì íŠ¸ í•™ìŠµ ê²°ê³¼ ìºì‹œ
    cached_project_knowledge = None
    learn_summary_info_path = "/home/bes/BES_QE_RAG/learn_summary_info.json"
    learn_all_info_path = "/home/bes/BES_QE_RAG/learn_all_info.json"

    def __init__(self,
                testcase_db_path="/home/bes/BES_QE_RAG/testcase_rag/testcase_vectordb",           # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DB í´ë”
                automation_db_path="/home/bes/BES_QE_RAG/automation_rag/automation_vectordb",       # ìë™í™” ì½”ë“œ DB í´ë”
                testcase_collection_name="testcase_vectordb",        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì»¬ë ‰ì…˜ëª…
                automation_collection_name="test_automation_functions",     # ìë™í™” ì½”ë“œ ì»¬ë ‰ì…˜ëª…
                testcase_embedding_model="intfloat/multilingual-e5-large",        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìš© ì„ë² ë”© ëª¨ë¸
                automation_embedding_model="BAAI/bge-m3", # ìë™í™” ì½”ë“œìš© ì„ë² ë”© ëª¨ë¸
                lm_studio_url: str = "http://127.0.0.1:1234/v1",
                lm_studio_model: str = "qwen/qwen3-coder-30b"
                ):
        
        self.testcase_db_path = testcase_db_path
        self.automation_db_path = automation_db_path
        self.testcase_collection_name = testcase_collection_name
        self.automation_collection_name = automation_collection_name
        self.testcase_embedding_model = testcase_embedding_model
        self.automation_embedding_model = automation_embedding_model
        self.lm_studio_url = lm_studio_url
        self.lm_studio_model = lm_studio_model
        
        self.llm = LMStudioLLM(
            base_url=lm_studio_url,
            model_name=lm_studio_model,
            temperature=0.1,
            max_tokens=70000  # ìë™í™” ì½”ë“œ ìƒì„±ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
        )
    
        # í´ë” ì¡´ì¬ í™•ì¸
        self._check_db_directories()
        
        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìš© ì„ë² ë”© ëª¨ë¸ ì„¤ì • (GPU ì‚¬ìš©)
        print(f"ğŸ”§ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìš© ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {testcase_embedding_model}")
        testcase_model_kwargs = {'device': 'cuda', 'trust_remote_code': True}
        testcase_encode_kwargs = {'normalize_embeddings': True, 'batch_size': 4}
        
        self.testcase_embeddings = HuggingFaceEmbeddings(
            model_name=testcase_embedding_model,
            model_kwargs=testcase_model_kwargs,
            encode_kwargs=testcase_encode_kwargs
        )
        print(f"âœ… í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # ìë™í™” ì½”ë“œìš© ì„ë² ë”© ëª¨ë¸ ì„¤ì • (GPU ì‚¬ìš©)
        print(f"ğŸ”§ ìë™í™” ì½”ë“œìš© ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {automation_embedding_model}")
        automation_model_kwargs = {'device': 'cuda', 'trust_remote_code': True}
        automation_encode_kwargs = {'normalize_embeddings': True, 'batch_size': 4}
        
        self.automation_embeddings = HuggingFaceEmbeddings(
            model_name=automation_embedding_model,
            model_kwargs=automation_model_kwargs,
            encode_kwargs=automation_encode_kwargs
        )
        print(f"âœ… ìë™í™” ì½”ë“œ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # 2ê°œì˜ ë²¡í„° ì €ì¥ì†Œ ì—°ê²° (ê°ê° ë‹¤ë¥¸ í´ë”ì™€ ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸)
        self.testcase_vectorstore = self._connect_to_chroma(
            self.testcase_db_path, 
            self.testcase_collection_name, 
            self.testcase_embeddings,
            "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤",
            testcase_embedding_model
        )
        self.automation_vectorstore = self._connect_to_chroma(
            self.automation_db_path, 
            self.automation_collection_name, 
            self.automation_embeddings,
            "ìë™í™” ì½”ë“œ",
            automation_embedding_model
        )
        
    
    def _check_db_directories(self):
        """DB ë””ë ‰í„°ë¦¬ ì¡´ì¬ í™•ì¸"""
        print("ğŸ“ ChromaDB ë””ë ‰í„°ë¦¬ í™•ì¸ ì¤‘...")
        
        if not os.path.exists(self.testcase_db_path):
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DB ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.testcase_db_path}")
            print(f"   ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
        else:
            print(f"âœ… í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DB ë””ë ‰í„°ë¦¬ í™•ì¸: {self.testcase_db_path}")
        
        if not os.path.exists(self.automation_db_path):
            print(f"âš ï¸ ìë™í™” ì½”ë“œ DB ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.automation_db_path}")
            print(f"   ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
        else:
            print(f"âœ… ìë™í™” ì½”ë“œ DB ë””ë ‰í„°ë¦¬ í™•ì¸: {self.automation_db_path}")
    
    def _connect_to_chroma(self, persist_directory: str, collection_name: str, 
                          embedding_function, db_type: str, embedding_model_name: str) -> Chroma:
        """ê°œë³„ ChromaDB í´ë”ì˜ ì»¬ë ‰ì…˜ì— íŠ¹ì • ì„ë² ë”© ëª¨ë¸ë¡œ ì—°ê²°"""
        try:
            vectorstore = Chroma(
                collection_name=collection_name,
                embedding_function=embedding_function,
                persist_directory=persist_directory  # ê°ê° ë‹¤ë¥¸ ê²½ë¡œ ì‚¬ìš©
            )
            print(f"âœ… ChromaDB '{persist_directory}/{collection_name}' ({db_type}) ì—°ê²° ì™„ë£Œ")
            print(f"   ğŸ§  ì„ë² ë”© ëª¨ë¸: {embedding_model_name}")
            
            # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
            try:
                collection = vectorstore.get()
                doc_count = len(collection.get('ids', []))
                print(f"   ğŸ“Š {db_type} ë¬¸ì„œ ìˆ˜: {doc_count}ê°œ")
            except Exception as e:
                print(f"   â„¹ï¸ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ë¶ˆê°€: {e}")
            
            return vectorstore
        except Exception as e:
            print(f"âŒ ChromaDB '{persist_directory}' ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    

#RAG_Pipeline(RAG ê¸°ë³¸ê°’)ì„ ìƒì†ë°›ì•„ í…ŒìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ í•¨ìˆ˜ë¥¼ ìƒì„±
class RAG_Function(RAG_Pipeline) :
    async def retrieve_test_case(self, query: str) -> List[Dict]:
        try:
            # ì¿¼ë¦¬ì—ì„œ issue_key, step_index, number ì¶”ì¶œ
            # ì˜ˆì‹œ:
            # "COMMONR-30ì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í… 2ë²ˆ" -> issue_key="COMMONR-30", step_index="2", number=None
            # "COMMONR-30ì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í… 1_2ë²ˆ" -> issue_key="COMMONR-30", step_index="1", number="2"
            # "COMMONR-30ì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í… 1ë²ˆì˜ 2ë²ˆ" -> issue_key="COMMONR-30", step_index="1", number="2"

            issue_key_match = re.search(r'(COMMONR-\d+)', query)

            # step_index_number í˜•ì‹ (ì˜ˆ: "ìŠ¤í… 1_2")
            step_number_match = re.search(r'ìŠ¤í…\s*(\d+)_(\d+)', query)
            # step_indexë§Œ (ì˜ˆ: "ìŠ¤í… 1")
            step_index_match = re.search(r'ìŠ¤í…\s*(\d+)', query)
            # "ìŠ¤í… 1ë²ˆì˜ 2ë²ˆ" í˜•ì‹
            step_of_number_match = re.search(r'ìŠ¤í…\s*(\d+).*?(\d+)ë²ˆ', query)

            if not issue_key_match:
                print(f"âš ï¸ ì¿¼ë¦¬ì—ì„œ issue_keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {query}")
                return []

            issue_key = issue_key_match.group(1)
            step_index = None
            number = None

            # number ì¶”ì¶œ ìš°ì„ ìˆœìœ„
            if step_number_match:
                # "ìŠ¤í… 1_2" í˜•ì‹
                step_index = step_number_match.group(1)
                number = step_number_match.group(2)
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key}, step_index={step_index}, number={number}")
            elif step_of_number_match:
                # "ìŠ¤í… 1ë²ˆì˜ 2ë²ˆ" í˜•ì‹
                step_index = step_of_number_match.group(1)
                number = step_of_number_match.group(2)
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key}, step_index={step_index}, number={number}")
            elif step_index_match:
                # "ìŠ¤í… 1" í˜•ì‹ (number ì—†ìŒ)
                step_index = step_index_match.group(1)
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key}, step_index={step_index} (ì „ì²´)")
            else:
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key} (ëª¨ë“  ìŠ¤í…)")

            # ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„± (step_indexê¹Œì§€ë§Œ í•„í„°ë§, numberëŠ” ë‚˜ì¤‘ì— LLMì—ê²Œ ì „ë‹¬)
            if step_index:
                where_filter = {
                    "$and": [
                        {"issue_key": {"$eq": issue_key}},
                        {"step_index": {"$eq": step_index}}
                    ]
                }
            else:
                where_filter = {"issue_key": {"$eq": issue_key}}

            # ChromaDBì—ì„œ ì§ì ‘ ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ ê²€ìƒ‰
            collection = self.testcase_vectorstore.get(where=where_filter)

            if not collection or not collection.get('ids'):
                print(f"   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
            testcase_results = []
            ids = collection.get('ids', [])
            documents = collection.get('documents', [])
            metadatas = collection.get('metadatas', [])

            for i in range(len(ids)):
                testcase_results.append({
                    "content": documents[i] if i < len(documents) else "",
                    "metadata": metadatas[i] if i < len(metadatas) else {},
                })

            print(f"   ğŸ“š í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DBì—ì„œ {len(testcase_results)}ê°œ ê²€ìƒ‰ë¨")
            print(f"ğŸ“Š ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ {len(testcase_results)}ê°œ")
            return testcase_results

        except Exception as e:
            print(f"âŒ ë²¡í„° DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []


    def _safe_parse_json(self, response_text: str, default: dict) -> dict:
        """ì•ˆì „í•œ JSON íŒŒì‹± í—¬í¼"""
        import re
        import json

        try:
            # ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ strì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if hasattr(response_text, 'content'):
                response_text = response_text.content

            response_str = str(response_text)

            # ë””ë²„ê¹…: ì‘ë‹µ ì•ë¶€ë¶„ ì¶œë ¥
            print(f"   ğŸ” [JSON íŒŒì‹±] ì‘ë‹µ ê¸¸ì´: {len(response_str)}ì")
            print(f"   ğŸ” [JSON íŒŒì‹±] ì‘ë‹µ ì• 200ì: {response_str[:200]}")

            # JSON ë¸”ë¡ ì°¾ê¸° - greedy ë°©ì‹ìœ¼ë¡œ ë³€ê²½
            patterns = [
                r'```json\s*(\{.*\})\s*```',  # âœ… .* ëŠ” ìµœëŒ€ ë§¤ì¹­ - ì¤‘ì²©ëœ { } ì²˜ë¦¬ ê°€ëŠ¥
                r'```\s*(\{.*\})\s*```',
                r'(\{.*\})'
            ]

            for i, pattern in enumerate(patterns):
                match = re.search(pattern, response_str, re.DOTALL)
                if match:
                    json_str = match.group(1).strip()
                    try:
                        parsed = json.loads(json_str)
                        print(f"   âœ… [JSON íŒŒì‹±] íŒ¨í„´ {i+1}ë¡œ ì„±ê³µ, extracted_info ê°œìˆ˜: {len(parsed.get('extracted_info', []))}")
                        return parsed
                    except json.JSONDecodeError as je:
                        print(f"   âš ï¸ [JSON íŒŒì‹±] íŒ¨í„´ {i+1} ë§¤ì¹­ë˜ì—ˆìœ¼ë‚˜ íŒŒì‹± ì‹¤íŒ¨: {je}")
                        continue

            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"   âŒ [JSON íŒŒì‹±] ëª¨ë“  íŒ¨í„´ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
            return default

        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return default



    def load_learn_summary_info(self) -> Optional[str]:
        """Step 5 ìµœì¢… ìš”ì•½ ì •ë³´ ë¡œë“œ"""
        import json

        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if RAG_Pipeline.cached_project_knowledge is not None:
            print("âœ… [Step 5 ìš”ì•½] ë©”ëª¨ë¦¬ì—ì„œ ë¡œë“œ (ì¦‰ì‹œ)")
            return RAG_Pipeline.cached_project_knowledge

        # 2. íŒŒì¼ ìºì‹œ í™•ì¸
        if os.path.exists(RAG_Pipeline.learn_summary_info_path):
            try:
                with open(RAG_Pipeline.learn_summary_info_path, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    knowledge = cached_data.get('knowledge', '')
                    timestamp = cached_data.get('timestamp', '')
                    print(f"âœ… [Step 5 ìš”ì•½] íŒŒì¼ì—ì„œ ë¡œë“œ (ì €ì¥ ì‹œê°: {timestamp})")
                    # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥
                    RAG_Pipeline.cached_project_knowledge = knowledge
                    return knowledge
            except Exception as e:
                print(f"âš ï¸ [Step 5 ìš”ì•½] íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None

        print("â„¹ï¸ [Step 5 ìš”ì•½] ìºì‹œ ì—†ìŒ - ìƒˆë¡œ í•™ìŠµ í•„ìš”")
        return None


    async def generate_code(self, test_case_info: List[Dict], test_case_analysis: str = "") -> str:
        """
        âœ¨ ê°„ì†Œí™”: í•™ìŠµëœ ë‚´ìš©ë§Œ ì‚¬ìš© (íŒŒì¼ ì¬ë¡œë”© ë¶ˆí•„ìš”)
        âœ¨ ê°œì„ : í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ë‚´ìš© í¬í•¨
        """
        import os
        import json

        try:
            print("--- 3. âš¡ ìë™í™”ì½”ë“œ ìƒì„± (ìºì‹œëœ í•™ìŠµ ë‚´ìš© ê¸°ë°˜) ---")

            # âœ¨ í”„ë¡œì íŠ¸ ì „ì²´ í•™ìŠµ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
            accumulated_knowledge = self.load_learn_summary_info()
            print(f"   âœ… í•™ìŠµ ë‚´ìš© ë¡œë“œ ì™„ë£Œ ({len(accumulated_knowledge):,}ì)")

            # âŒ Proto/Core íŒŒì¼ ì¬ë¡œë”© ì œê±° (ì´ë¯¸ accumulated_knowledgeì— í¬í•¨ë¨)

            #í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ infoë¥¼ ì¿¼ë¦¬ í˜•íƒœë¡œ ë°”ê¿ˆ
            self.automation_plan_prompt_template = PromptTemplate(
                input_variables=[
              "accumulated_knowledge",  # âœ¨ ëª¨ë“  íŒŒì¼ í•™ìŠµ ê²°ê³¼
              "test_case_content",
              "test_case_metadata",
              "test_case_analysis"  # âœ¨ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼
          ],
          template="""
ë‹¹ì‹ ì€ GSDK Python ìë™í™” í…ŒìŠ¤íŠ¸ ì½”ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

---

## ğŸ“š í•™ìŠµ ë‚´ìš© (ì´ë¯¸ í•™ìŠµ ì™„ë£Œ)

{accumulated_knowledge}

ìœ„ ë‚´ìš©ì€ ë‹¤ìŒì„ **ì „ì²´ í•™ìŠµ**í•œ ê²°ê³¼ì…ë‹ˆë‹¤:
- `biostar/proto/` - Proto ë©”ì‹œì§€ ì •ì˜
- `biostar/service/` - gRPC ì„œë¹„ìŠ¤ êµ¬í˜„ (pb2)
- `demo/test/` - ì‹¤ì œ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ **â­ ì£¼ìš” ì°¸ì¡°**
- `demo/manager.py` - ServiceManager API
- `demo/test/util.py` - í—¬í¼ í•¨ìˆ˜
- `example/` - API ì‚¬ìš© íŒ¨í„´

**ì´ í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ ê²ƒë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.**

---

## ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼

{test_case_analysis}

ìœ„ ë¶„ì„ì˜ **8ê°œ í•­ëª© ì „ì²´**ë¥¼ ì½”ë“œì— ë°˜ì˜í•˜ì„¸ìš”:
1. í…ŒìŠ¤íŠ¸ ëª©ì  ì´í•´
2. í•„ìš”í•œ ê¸°ìˆ  ìš”ì†Œ (Proto, gRPC, example, ServiceManager, ë°ì´í„°)
3. ê²€ì¦ í•­ëª© (Expected Result)
4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìš”êµ¬ì‚¬í•­
5. í…ŒìŠ¤íŠ¸ ë² ì´ìŠ¤ í´ë˜ìŠ¤ ìš”êµ¬ì‚¬í•­
6. ìœ í‹¸ë¦¬í‹° ìš”êµ¬ì‚¬í•­
7. ì‹¤ì œ ì½”ë“œ íŒ¨í„´ ì°¸ì¡°
8. ì „ì²´ ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­

---

## ğŸ“‹ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë‚´ìš©

{test_case_content}

**ë©”íƒ€ë°ì´í„°**:
{test_case_metadata}

---

## ğŸ¯ ì½”ë“œ ìƒì„± ì§€ì¹¨

### 1ï¸âƒ£ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ êµ¬í˜„
- í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ì˜ ìš”êµ¬ì‚¬í•­ì„ **í•™ìŠµ ë‚´ìš©ì—ì„œ ë§¤ì¹­**
- í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ íŒŒì¼, í•¨ìˆ˜, APIë§Œ ì‚¬ìš©
- demo/test/ì˜ ì„±ê³µí•œ ì½”ë“œ íŒ¨í„´ ì°¸ì¡°

### 2ï¸âƒ£ í•„ìˆ˜ êµ¬ì¡° (CLAUDE.md ì›Œí¬í”Œë¡œìš°)
```python
# ğŸ“¦ í•„ìˆ˜ Import (í•­ìƒ í¬í•¨)
import unittest
import util
from testCOMMONR import *
from manager import ServiceManager

# ğŸ“¦ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë§Œ Import
import {{service}}_pb2  # í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ pb2ë§Œ
# import os, json ë“± (í•„ìš” ì‹œ)

# ğŸ—ï¸ í´ë˜ìŠ¤ êµ¬ì¡°
class testCOMMONR_{{issue_number}}_{{step_index}}(TestCOMMONR):
    \"\"\"ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…\"\"\"

    def testCommonr_{{issue_number}}_{{step_index}}_{{number}}_{{description}}(self):
        \"\"\"
        í•´ë‹¹ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
        - TCì˜ Test Step X êµ¬í˜„
        - TCì˜ Expected Result Y ê²€ì¦
        \"\"\"

        # 1. Capability ì²´í¬ (í•„ìš” ì‹œ)
        # ë¶„ì„ ê²°ê³¼ì—ì„œ ìš”êµ¬ëœ capabilityë§Œ ì²´í¬

        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (JSON ìš°ì„ )
        # í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ Builder íŒ¨í„´ ì‚¬ìš©
        {{data}} = None
        for entry in os.listdir("./data"):
            if entry.startswith("{{data}}") and entry.endswith(".json"):
                with open("./data/" + entry, encoding='UTF-8') as f:
                    {{data}} = json.load(f, cls=util.{{Data}}Builder)
                    break

        # 3. API í˜¸ì¶œ (í•™ìŠµ ë‚´ìš©ì˜ ServiceManager ë©”ì„œë“œ ì‚¬ìš©)
        # ë¶„ì„ ê²°ê³¼ì—ì„œ ì°¾ì€ APIë§Œ í˜¸ì¶œ

        # 4. ê²€ì¦ (Expected Result ì „ì²´ êµ¬í˜„)
        # unittest.assertEqual, assertTrue ë“± ì‚¬ìš©
```

### 3ï¸âƒ£ ë°ì´í„° ìƒì„± ì „ëµ
- **ìš°ì„ ìˆœìœ„ 1**: JSON íŒŒì¼ ë¡œë“œ (util.pyì˜ Builder ì‚¬ìš©)
- **ìš°ì„ ìˆœìœ„ 2**: ê¸°ì¡´ ë°ì´í„° ìˆ˜ì • (JSON ê°’ ê¸°ë°˜)
- **util.py ì‚¬ìš©ë²•**: `util.í•¨ìˆ˜ëª…()` í˜•íƒœ (ì§ì ‘ import ê¸ˆì§€)

### 4ï¸âƒ£ ê²€ì¦ êµ¬í˜„
- **Expected Resultì˜ ëª¨ë“  í•­ëª© ê²€ì¦**
- unittest assertion ì‚¬ìš©
- EventMonitor í•„ìš” ì‹œ ì‚¬ìš© (ë¶„ì„ ê²°ê³¼ ì°¸ì¡°)

### 5ï¸âƒ£ ê¸ˆì§€ ì‚¬í•­
- âŒ setUp/tearDown ì¬ì •ì˜ ê¸ˆì§€
- âŒ í•™ìŠµ ë‚´ìš©ì— ì—†ëŠ” í•¨ìˆ˜/API ì‚¬ìš© ê¸ˆì§€
- âŒ Builder ì§ì ‘ import ê¸ˆì§€ (util ì‚¬ìš©)
- âŒ pb2 import í›„ ë¯¸ì‚¬ìš© ê¸ˆì§€
- âŒ êµ¬ì²´ì  í•¨ìˆ˜ëª… ì˜ˆì‹œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬ ê¸ˆì§€

---

## ğŸ“ ì¶œë ¥ ìš”êµ¬ì‚¬í•­

1. **íŒŒì¼ëª…**: `testCOMMONR_{{ìˆ«ì}}_{{step_index}}.py`
   - ì˜ˆ: COMMONR-21 â†’ testCOMMONR_21_1.py

2. **í´ë˜ìŠ¤ëª…**: `testCOMMONR_{{ìˆ«ì}}_{{step_index}}(TestCOMMONR)`

3. **í•¨ìˆ˜ëª…**: `testCommonr_{{ìˆ«ì}}_{{step_index}}_{{N}}_{{ì„¤ëª…}}()`
   - N: 1, 2, 3... (ìˆœì°¨ ì¦ê°€)
   - ì„¤ëª…: í…ŒìŠ¤íŠ¸ ë‚´ìš© ìš”ì•½

4. **ì™„ì „í•œ Python ì½”ë“œ ìƒì„±**
   - ëª¨ë“  Test Step êµ¬í˜„
   - ëª¨ë“  Expected Result ê²€ì¦
   - ë°ì´í„° ìƒì„± ì „ëµ ì¤€ìˆ˜

---

âš ï¸ **ìµœì¢… ì²´í¬**
- [ ] í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ì˜ 8ê°œ í•­ëª© ì „ì²´ ë°˜ì˜
- [ ] í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ ê²ƒë§Œ ì‚¬ìš© (ì¶”ì¸¡ ê¸ˆì§€)
- [ ] demo/test/ì˜ ì„±ê³µ íŒ¨í„´ ì°¸ì¡°
- [ ] Expected Result ì „ì²´ ê²€ì¦
- [ ] util.í•¨ìˆ˜ëª…() í˜•íƒœ ì‚¬ìš©
- [ ] pb2 import ì‹œ ë°˜ë“œì‹œ ì‚¬ìš©

**ì™„ì „í•œ testCOMMONR ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸ ì½”ë“œ ê³„íšì„ ìƒì„±í•˜ì„¸ìš”.**
Think step by step. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ë„ ê´œì°®ìŠµë‹ˆë‹¤.
""")
            
            
            self.automation_prompt_template = PromptTemplate(
                input_variables=[
              "accumulated_knowledge",  # âœ¨ ëª¨ë“  íŒŒì¼ í•™ìŠµ ê²°ê³¼
              "test_case_content",
              "test_case_analysis",  # âœ¨ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼
              "generated_plan"
          ],
          template="""
ë‹¹ì‹ ì€ GSDK Python ìë™í™” í…ŒìŠ¤íŠ¸ ì½”ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

---

## ğŸ“š í•™ìŠµ ë‚´ìš© (ì´ë¯¸ í•™ìŠµ ì™„ë£Œ)

{accumulated_knowledge}

ìœ„ ë‚´ìš©ì€ ë‹¤ìŒì„ **ì „ì²´ í•™ìŠµ**í•œ ê²°ê³¼ì…ë‹ˆë‹¤:
- `biostar/proto/` - Proto ë©”ì‹œì§€ ì •ì˜
- `biostar/service/` - gRPC ì„œë¹„ìŠ¤ êµ¬í˜„ (pb2)
- `demo/test/` - ì‹¤ì œ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ **â­ ì£¼ìš” ì°¸ì¡°**
- `demo/manager.py` - ServiceManager API
- `demo/test/util.py` - í—¬í¼ í•¨ìˆ˜
- `example/` - API ì‚¬ìš© íŒ¨í„´

**ì´ í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ ê²ƒë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.**

---

## ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼

{test_case_analysis}

ìœ„ ë¶„ì„ì˜ **8ê°œ í•­ëª© ì „ì²´**ë¥¼ ì½”ë“œì— ë°˜ì˜í•˜ì„¸ìš”:
1. í…ŒìŠ¤íŠ¸ ëª©ì  ì´í•´
2. í•„ìš”í•œ ê¸°ìˆ  ìš”ì†Œ (Proto, gRPC, example, ServiceManager)
3. **ê²€ì¦ í•­ëª©** â­ **ê°€ì¥ ì¤‘ìš”** (Test Step ì ˆì°¨, Test Data ë°˜ì˜, Expected Result ê²€ì¦)
4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìš”êµ¬ì‚¬í•­
5. í…ŒìŠ¤íŠ¸ ë² ì´ìŠ¤ í´ë˜ìŠ¤ ìš”êµ¬ì‚¬í•­
6. ìœ í‹¸ë¦¬í‹° ìš”êµ¬ì‚¬í•­
7. ì‹¤ì œ ì½”ë“œ íŒ¨í„´ ì°¸ì¡°
8. ì „ì²´ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­

**íŠ¹íˆ í•­ëª© 3ì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤:**
- TCì˜ Test Step ì ˆì°¨ëŒ€ë¡œ ì½”ë“œë¥¼ ì‘ì„±í–ˆëŠ”ê°€?
- TCì˜ Test Data ê°’ì„ ë°˜ì˜í–ˆëŠ”ê°€?
- TCì˜ Expected ResultëŒ€ë¡œ ê²€ì¦í–ˆëŠ”ê°€?

---

## ğŸ“‹ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë‚´ìš©

{test_case_content}

---

## ğŸ“‹ ìë™í™”ì½”ë“œ ê³„íš

{generated_plan}

ìœ„ ê³„íšì„ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

---

## ğŸ¯ ì½”ë“œ ìƒì„± ì§€ì¹¨

### 1ï¸âƒ£ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ êµ¬í˜„ (8ê°œ í•­ëª© ì²´í¬)

**í•­ëª© 3: Test Step / Data / Expected Result êµ¬í˜„** â­ ìµœìš°ì„ 
- TCì˜ **Test Step ì ˆì°¨**ë¥¼ ìˆœì„œëŒ€ë¡œ êµ¬í˜„
- TCì˜ **Test Data** ê°’ì„ ì •í™•íˆ ë°˜ì˜
- TCì˜ **Expected Result** ëª¨ë“  í•­ëª©ì„ ê²€ì¦

**í•­ëª© 2: í•„ìš”í•œ ê¸°ìˆ  ìš”ì†Œ í™œìš©**
- í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ Proto ë©”ì‹œì§€ë§Œ ì‚¬ìš©
- í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ gRPC ì„œë¹„ìŠ¤/ë©”ì„œë“œë§Œ í˜¸ì¶œ
- ServiceManager API í™œìš©

**í•­ëª© 4: í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±**
- JSON íŒŒì¼ ë¡œë“œ ìš°ì„  (util.pyì˜ Builder í™œìš©)
- í•„ìš” ì‹œ ê¸°ì¡´ ë°ì´í„° ìˆ˜ì • (JSON ê°’ ê¸°ë°˜)

**í•­ëª© 7: demo/test/ ì„±ê³µ íŒ¨í„´ ì°¸ì¡°**
- import íŒ¨í„´
- ë°ì´í„° ì²˜ë¦¬ ë°©ì‹
- API í˜¸ì¶œ íë¦„
- ê²€ì¦ ë°©ë²•

---

### 2ï¸âƒ£ í•„ìˆ˜ êµ¬ì¡° (CLAUDE.md ì›Œí¬í”Œë¡œìš°)

```python
# ğŸ“¦ í•„ìˆ˜ Import (í•­ìƒ í¬í•¨)
import unittest
import util
from testCOMMONR import *
from manager import ServiceManager

# ğŸ“¦ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë§Œ Import
import {{service}}_pb2  # í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ pb2ë§Œ
import os, json  # í•„ìš” ì‹œ

# ğŸ—ï¸ í´ë˜ìŠ¤ êµ¬ì¡°
class testCOMMONR_{{issue_number}}_{{step_index}}(TestCOMMONR):
    \"\"\"ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…\"\"\"

    def testCommonr_{{issue_number}}_{{step_index}}_{{number}}_{{description}}(self):
        \"\"\"
        í•´ë‹¹ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
        - TCì˜ Test Step X êµ¬í˜„
        - TCì˜ Test Data ë°˜ì˜
        - TCì˜ Expected Result Y ê²€ì¦
        \"\"\"

        # 1. Capability ì²´í¬ (í•„ìš” ì‹œ)
        # ë¶„ì„ ê²°ê³¼ í•­ëª© 2ì—ì„œ ìš”êµ¬ëœ capabilityë§Œ ì²´í¬

        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (í•­ëª© 4 ë°˜ì˜)
        # JSON ìš°ì„ , í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ Builder íŒ¨í„´ ì‚¬ìš©
        {{data}} = None
        for entry in os.listdir("./data"):
            if entry.startswith("{{data}}") and entry.endswith(".json"):
                with open("./data/" + entry, encoding='UTF-8') as f:
                    {{data}} = json.load(f, cls=util.{{Data}}Builder)
                    break

        # í•„ìš” ì‹œ ê¸°ì¡´ ë°ì´í„° ìˆ˜ì • (JSON ê°’ ê¸°ë°˜)

        # 3. API í˜¸ì¶œ (í•­ëª© 2 ë°˜ì˜)
        # í•™ìŠµ ë‚´ìš©ì˜ ServiceManager ë©”ì„œë“œ ì‚¬ìš©
        # TCì˜ Test Step ì ˆì°¨ëŒ€ë¡œ í˜¸ì¶œ

        # 4. ê²€ì¦ (í•­ëª© 3 ë°˜ì˜)
        # TCì˜ Expected Result ì „ì²´ êµ¬í˜„
        # unittest.assertEqual, assertTrue ë“± ì‚¬ìš©
```

---

### 3ï¸âƒ£ ë°ì´í„° ìƒì„± ì „ëµ (í•­ëª© 4)

**ìš°ì„ ìˆœìœ„ 1: JSON íŒŒì¼ ë¡œë“œ**
```python
{{data}} = None
for entry in os.listdir("./data"):
    if entry.startswith("{{data}}") and entry.endswith(".json"):
        with open("./data/" + entry, encoding='UTF-8') as f:
            {{data}} = json.load(f, cls=util.{{Data}}Builder)
            break
```

**ìš°ì„ ìˆœìœ„ 2: ê¸°ì¡´ ë°ì´í„° ìˆ˜ì •**
- JSON ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ í•„ìš”í•œ ë°ì´í„° ìƒì„±
- ì˜ˆ: ì§€ë¬¸+PIN ìœ ì € í•„ìš” â†’ ê¸°ì¡´ ìœ ì €ì˜ ì§€ë¬¸+PIN ê°’ í™œìš©

**util.py ì‚¬ìš©ë²•:**
- `util.í•¨ìˆ˜ëª…()` í˜•íƒœë¡œ ì‚¬ìš©
- Builder ì§ì ‘ import ê¸ˆì§€

---

### 4ï¸âƒ£ Test Step / Data / Expected Result êµ¬í˜„ (í•­ëª© 3) â­ ìµœìš°ì„ 

**TCì˜ Test Step ì ˆì°¨ êµ¬í˜„:**
- TCì˜ ê° Stepì„ ìˆœì„œëŒ€ë¡œ ì½”ë“œë¡œ ì‘ì„±
- í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ API/í•¨ìˆ˜ë§Œ ì‚¬ìš©

**TCì˜ Test Data ë°˜ì˜:**
- TCì˜ Data í•­ëª©ì— ëª…ì‹œëœ ë°ì´í„° ê°’ ì‚¬ìš©
- JSON íŒŒì¼ ë˜ëŠ” Builderë¡œ ìƒì„±

**TCì˜ Expected Result ê²€ì¦:**
- TCì˜ ëª¨ë“  Expected Result í•­ëª© ê²€ì¦
- unittest assertion ì‚¬ìš© (assertEqual, assertTrue ë“±)
- EventMonitor í•„ìš” ì‹œ ì‚¬ìš©

---

### 5ï¸âƒ£ ê¸ˆì§€ ì‚¬í•­

- âŒ setUp/tearDown ì¬ì •ì˜ ê¸ˆì§€
- âŒ í•™ìŠµ ë‚´ìš©ì— ì—†ëŠ” í•¨ìˆ˜/API ì‚¬ìš© ê¸ˆì§€
- âŒ Builder ì§ì ‘ import ê¸ˆì§€ (util ì‚¬ìš©)
- âŒ pb2 import í›„ ë¯¸ì‚¬ìš© ê¸ˆì§€
- âŒ íŒŒì¼ ë§¨ ìœ„ì— ì£¼ì„ (# testCOMMONR_21_1.py) ê¸ˆì§€

---

## ğŸ“ ì¶œë ¥ ìš”êµ¬ì‚¬í•­

1. **íŒŒì¼ëª…**: `testCOMMONR_{{ìˆ«ì}}_{{step_index}}.py`
   - ì˜ˆ: COMMONR-21 â†’ testCOMMONR_21_1.py

2. **í´ë˜ìŠ¤ëª…**: `testCOMMONR_{{ìˆ«ì}}_{{step_index}}(TestCOMMONR)`

3. **í•¨ìˆ˜ëª…**: `testCommonr_{{ìˆ«ì}}_{{step_index}}_{{N}}_{{ì„¤ëª…}}()`
   - N: 1, 2, 3... (ìˆœì°¨ ì¦ê°€)
   - ì„¤ëª…: í…ŒìŠ¤íŠ¸ ë‚´ìš© ìš”ì•½

4. **ì™„ì „í•œ Python ì½”ë“œ ìƒì„±**
   - TCì˜ ëª¨ë“  Test Step êµ¬í˜„
   - TCì˜ Test Data ë°˜ì˜
   - TCì˜ ëª¨ë“  Expected Result ê²€ì¦
   - ë°ì´í„° ìƒì„± ì „ëµ ì¤€ìˆ˜
   - demo/test/ íŒ¨í„´ ì°¸ì¡°

---

âš ï¸ **ìµœì¢… ì²´í¬**

**í•µì‹¬ ì²´í¬ (í•­ëª© 3: Test Step / Data / Expected Result)** â­ ê°€ì¥ ì¤‘ìš”
- [ ] TCì˜ Test Step ì ˆì°¨ëŒ€ë¡œ êµ¬í˜„
- [ ] TCì˜ Test Data ê°’ ë°˜ì˜
- [ ] TCì˜ Expected Result ì „ì²´ ê²€ì¦

**ê¸°íƒ€ ì²´í¬**
- [ ] í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ì˜ 8ê°œ í•­ëª© ì „ì²´ ë°˜ì˜
- [ ] í•™ìŠµ ë‚´ìš©ì—ì„œ ì°¾ì€ ê²ƒë§Œ ì‚¬ìš© (ì¶”ì¸¡ ê¸ˆì§€)
- [ ] demo/test/ì˜ ì„±ê³µ íŒ¨í„´ ì°¸ì¡°
- [ ] util.í•¨ìˆ˜ëª…() í˜•íƒœ ì‚¬ìš©
- [ ] pb2 import ì‹œ ë°˜ë“œì‹œ ì‚¬ìš©
- [ ] ë°ì´í„° ìƒì„± ì „ëµ ì¤€ìˆ˜ (ê° number í•¨ìˆ˜ë§ˆë‹¤)
- [ ] ê²€ì¦ ì½”ë“œ ì¶©ë¶„íˆ ì‘ì„± (ê¸¸ì–´ì ¸ë„ ë¨)

**ìƒì„± ê³„íšê³¼ TC ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, Test Step/Data/Expected Resultê°€ ì™„ë²½í•˜ê²Œ ì¶©ì¡±ë˜ëŠ” ì™„ì „í•œ testCOMMONR ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.**

Think step by step. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ë„ ê´œì°®ìŠµë‹ˆë‹¤.
""")

            # ê³„íš í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… (ê°„ì†Œí™”)
            formatted_plan_prompt = self.automation_plan_prompt_template.format(
                accumulated_knowledge=accumulated_knowledge,
                test_case_content=test_case_info[0]['content'],
                test_case_metadata=test_case_info[0]['metadata'],
                test_case_analysis=test_case_analysis if test_case_analysis else "ë¶„ì„ ë‚´ìš© ì—†ìŒ"
            )

            print("--- ìë™í™”ì½”ë“œ ê³„íš í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ---")
            print(f"ê¸€ì ìˆ˜: {len(formatted_plan_prompt):,}ì (ê°„ì†Œí™”ë¨!)")

            # LLM í˜¸ì¶œ - ê³„íš ìƒì„±
            await cl.Message(content="**3-1. ğŸ“ ìë™í™”ì½”ë“œ ê³„íš ìƒì„± ì¤‘...**").send()
            print("   ğŸ”§ [ì½”ë“œ ìƒì„±] ìë™í™”ì½”ë“œ ê³„íš ìƒì„± ì¤‘...")
            generated_plans = await self.llm.ainvoke(formatted_plan_prompt)
            print("   âœ… [ì½”ë“œ ìƒì„±] ìë™í™”ì½”ë“œ ê³„íš ìƒì„± ì™„ë£Œ")
            await cl.Message(content=f"âœ… **ê³„íš ìƒì„± ì™„ë£Œ**\n\n```markdown\n{generated_plans[:500]}...\n```").send()

            # ì‹¤ì œ ì½”ë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… (ê°„ì†Œí™”)
            formatted_prompt = self.automation_prompt_template.format(
                accumulated_knowledge=accumulated_knowledge,
                test_case_content=test_case_info[0]['content'],
                test_case_analysis=test_case_analysis if test_case_analysis else "ë¶„ì„ ë‚´ìš© ì—†ìŒ",
                generated_plan=generated_plans
            )

            print("--- ìë™í™”ì½”ë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ---")
            print(f"ê¸€ì ìˆ˜: {len(formatted_prompt):,}ì (ê°„ì†Œí™”ë¨!)")

            # LLM í˜¸ì¶œ
            await cl.Message(content="**3-2. âš¡ ìµœì¢… ì½”ë“œ ìƒì„± ì¤‘...**").send()
            print("   ğŸ”§ [ì½”ë“œ ìƒì„±] ìµœì¢… ìë™í™”ì½”ë“œ ìƒì„± ì¤‘...")
            generated_code = await self.llm.ainvoke(formatted_prompt)
            print("   âœ… [ì½”ë“œ ìƒì„±] ìµœì¢… ìë™í™”ì½”ë“œ ìƒì„± ì™„ë£Œ")
            await cl.Message(content="âœ… **ì½”ë“œ ìƒì„± ì™„ë£Œ!**").send()

            # ì½”ë“œ ë°˜í™˜
            return generated_code
            
        except Exception as e:
            print(f"âŒ ìë™í™”ì½”ë“œ ê³„íš ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ìë™í™” ì½”ë“œ ê³„íš ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

class GraphState(TypedDict):
    # í•„ìˆ˜ ìƒíƒœë“¤
    original_query: str                     # ì‚¬ìš©ìì˜ ìµœì´ˆ ì§ˆë¬¸
    test_case_info: List[Dict]              # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ RAGì—ì„œ ì°¾ì€ ì •ë³´
    test_case_analysis: str                 # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ (ì»¤ë²„ë¦¬ì§€ í¬í•¨)
    retrieved_code_snippets: List[Dict]     # LLMì´ ì„ ë³„í•œ ìë™í™” ì½”ë“œ ì¡°ê°ë“¤
    cached_knowledge: str                   # ê¸°ì¡´ ìºì‹œëœ í•™ìŠµ ë‚´ìš©
    knowledge_comparison: str               # ê¸°ì¡´ ì§€ì‹ê³¼ ìƒˆ í•™ìŠµ ë‚´ìš© ë¹„êµ ê²°ê³¼
    should_relearn: bool                    # ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€
    missing_knowledge: str                  # í•™ìŠµ ë¹„êµ ê²°ê³¼ì—ì„œ ì¶”ì¶œí•œ ëˆ„ë½ëœ ì§€ì‹
    user_feedback: str                      # ì‚¬ìš©ì í”¼ë“œë°± (ì¬í•™ìŠµ ì„ íƒ ë“±)
    final_code: str                         # ìµœì¢… ìƒì„±ëœ ìë™í™” ì½”ë“œ
    reasoning_process: str                  # ì½”ë“œ ìƒì„± ì‹œ LLMì˜ ì¶”ë¡  ê³¼ì •
    # âœ¨ ì¶”ê°€
    conversation_history: List[Dict[str, str]]  # [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
    error: str                              # ì—ëŸ¬ ë°œìƒ ì‹œ ë©”ì‹œì§€


class RAG_Graph(RAG_Function) :
    def __init__(self, **kwargs):
        # **kwargsë¡œ ëª¨ë“  ì¸ìë¥¼ ë°›ì•„ ë¶€ëª¨ í´ë˜ìŠ¤ì— ì „ë‹¬
        super().__init__(**kwargs)
        self.graph = self._build_graph()
        
    # 1. ë…¸ë“œ ì •ì˜ ë©”ì„œë“œ
    async def testcase_rag_node(self, state: GraphState) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²€ìƒ‰ ë…¸ë“œ"""
        await cl.Message(content=" **1. ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...**").send()
        query = state['original_query']
        # ìƒì†ë°›ì€ retrieve_test_case ë©”ì„œë“œ í˜¸ì¶œ
        results = await self.retrieve_test_case(query)
        #chainlitì— ì‹¤ì‹œê°„ ê²°ê³¼ê°’ í‘œì‹œ
        await cl.Message(content=f"âœ… **í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ** \n```json\n{json.dumps(results, ensure_ascii=False, indent=2, default=str)}\n```").send()
        return {"test_case_info": results}

    async def analyze_testcase_node(self, state: GraphState) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ë…¸ë“œ - ì»¤ë²„ë¦¬ì§€ í‰ê°€ í¬í•¨"""
        print("âœ… current node : analyze_testcase_node")
        await cl.Message(content="**2. ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„¸ ë¶„ì„ ì¤‘...**").send()

        try:
            test_case_info = state.get("test_case_info", [])

            if not test_case_info:
                return {
                    "test_case_analysis": "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "error": "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì •ë³´ ëˆ„ë½"
                }

            # ê¸°ì¡´ ìºì‹œëœ ì§€ì‹ ë¡œë“œ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼/API ì •ë³´)
            learn_all_info_list = self.load_learn_all_info()  # List[Dict]

            # ëŒ€í™” ë°°ì—´ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í”„ë¡¬í”„íŠ¸ ì‚½ì…ìš© - contentë§Œ ì¶”ì¶œ)
            learn_all_info_text = "\n\n".join([
                msg.get('content', '')
                for msg in learn_all_info_list
            ])

            # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ìˆ˜í–‰ (ê¸°ì¡´ ì§€ì‹ê³¼ í•¨ê»˜)
            analysis_result = await self.analyze_test_case(test_case_info, learn_all_info_text)

            return {"test_case_analysis": analysis_result}

        except Exception as e:
            error_msg = f"analyze_testcase_node ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "test_case_analysis": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                "error": error_msg
            }
        

    async def compare_knowledge_node(self, state: GraphState) -> Dict[str, Any]:
        """ê¸°ì¡´ í•™ìŠµ ë‚´ìš©ê³¼ ìš”êµ¬ì‚¬í•­ ë¹„êµ ë…¸ë“œ - âœ… ì‚¬ìš©ì ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€ (3ê°€ì§€ ì˜µì…˜)"""
        print("âœ… current node : compare_knowledge_node")
        await cl.Message(content="**3. âš–ï¸ í•™ìŠµ ë‚´ìš© vs ìš”êµ¬ì‚¬í•­ ë¹„êµ ì¤‘...**").send()

        try:
            test_case_analysis = state.get("test_case_analysis", "")
            cached_knowledge = self.load_learn_summary_info()

            # âœ… ë¹„êµ ìˆ˜í–‰ (ëˆ„ë½ëœ ì§€ì‹ í¬í•¨)
            comparison_result, should_relearn, missing_knowledge = await self.compare_knowledge_with_requirements(
                cached_knowledge if cached_knowledge else "",
                test_case_analysis
            )

            # âœ… ë¹„êµ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ëª…í™•í•˜ê²Œ í‘œì‹œ
            comparison_display = f"""## ğŸ“Š í•™ìŠµ ë‚´ìš© ë¹„êµ ê²°ê³¼

    {comparison_result}

    ---

    **AI íŒë‹¨:** {'ğŸ”„ ì¦ë¶„ í•™ìŠµ í•„ìš”' if should_relearn else 'âœ… ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì¶©ë¶„'}

    **ëˆ„ë½ëœ ì§€ì‹:**
    ```
    {missing_knowledge if missing_knowledge else 'ì—†ìŒ'}
    ```
    """
            await cl.Message(content=comparison_display).send()

            # âœ… ì‚¬ìš©ìì—ê²Œ 2ê°€ì§€ ë²„íŠ¼ë§Œ ì œê³µ
            if should_relearn and missing_knowledge:
                # AIê°€ ì¦ë¶„ í•™ìŠµ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨
                prompt_msg = "âš ï¸ **AIê°€ ì¦ë¶„ í•™ìŠµì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.** ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
            else:
                # ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì¶©ë¶„
                prompt_msg = "âœ… **ê¸°ì¡´ í•™ìŠµìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤.** ì–´ë–»ê²Œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"

            res = await cl.AskActionMessage(
                content=prompt_msg,
                actions=[
                    cl.Action(name="use_missing", value="missing", label="ğŸ”„ ì¦ë¶„ í•™ìŠµ (AI ì¶”ì²œ)", payload={"choice": "missing"}),
                    cl.Action(name="skip", value="skip", label="â­ï¸ ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì§„í–‰", payload={"choice": "skip"}),
                ],
                timeout=120
            ).send()

            # âœ… ë””ë²„ê¹…: ì‘ë‹µ í™•ì¸
            print(f"ğŸ” [ë””ë²„ê¹…] AskActionMessage ì‘ë‹µ: {res}")

            # âœ… Chainlit ì‘ë‹µ íŒŒì‹± (timeout ì‹œ ê¸°ë³¸ê°’ "skip")
            if res:
                user_choice = res.get("name", "skip")  # "skip" ë˜ëŠ” "use_missing"
            else:
                # timeout ë˜ëŠ” ì‘ë‹µ ì—†ìŒ â†’ ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì§„í–‰
                user_choice = "skip"
                await cl.Message(content="â±ï¸ **ì‹œê°„ ì´ˆê³¼ - ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.**").send()

            print(f"ğŸ” [ë””ë²„ê¹…] ì‚¬ìš©ì ì„ íƒ: {user_choice}")

            # âœ… ì‚¬ìš©ì ì„ íƒ ê²°ê³¼ í‘œì‹œ
            if user_choice == "skip":
                await cl.Message(content="â­ï¸ **ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì½”ë“œ ìƒì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤.**").send()
                return {
                    "cached_knowledge": cached_knowledge if cached_knowledge else "",
                    "knowledge_comparison": comparison_result,
                    "missing_knowledge": "",
                    "should_relearn": False,
                    "user_feedback": ""  # âœ¨ ë¹ˆ ë¬¸ìì—´ â†’ generate_code
                }
            elif user_choice == "use_missing":
                await cl.Message(content="ğŸ”„ **AIê°€ ì œì•ˆí•œ ëˆ„ë½ëœ ì§€ì‹ìœ¼ë¡œ ì¦ë¶„ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.**").send()
                return {
                    "cached_knowledge": cached_knowledge if cached_knowledge else "",
                    "knowledge_comparison": comparison_result,
                    "missing_knowledge": missing_knowledge,
                    "should_relearn": True,
                    "user_feedback": missing_knowledge  # âœ¨ ëˆ„ë½ëœ ì§€ì‹ â†’ additional_learn
                }

        except Exception as e:
            error_msg = f"compare_knowledge_node ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return {
                "cached_knowledge": "",
                "knowledge_comparison": "ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                "missing_knowledge": "",
                "should_relearn": False,
                "user_feedback": "",
                "error": error_msg
            }
    
    
    async def generate_code_rag_node(self, state: GraphState) -> Dict[str, Any]:
        """ìë™í™”ì½”ë“œ ìƒì„± ë…¸ë“œ - í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ í¬í•¨"""
        print("âœ… current node : generate_code_rag_node")

        try:
            # GraphStateì—ì„œ í•„ìš”í•œ ì •ë³´ë“¤ ê°€ì ¸ì˜¤ê¸°
            test_case_info = state.get("test_case_info", [])
            test_case_analysis = state.get("test_case_analysis", "")

            if not test_case_info:
                return {
                    "final_code": "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì •ë³´ê°€ ì—†ì–´ ì½”ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "error": "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì •ë³´ ëˆ„ë½"
                }

            # ìë™í™” ì½”ë“œ ìƒì„± (í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„ ê²°ê³¼ í¬í•¨)
            generation_result = await self.generate_code(
                test_case_info,
                test_case_analysis
            )

            final_code = generation_result
            result = {
                "final_code": final_code
            }

            return result

        except Exception as e:
            error_msg = f"generate_code_rag_node ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "final_code": "ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": error_msg
            }
            
    async def learn_project_node(self, state: GraphState) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ìµœì´ˆ í•™ìŠµ ë…¸ë“œ - ìºì‹œ í™•ì¸ í›„ í•„ìš” ì‹œ í•™ìŠµ"""
        print("âœ… current node : learn_project_node")

        # ìºì‹œ í™•ì¸
        learn_summary_info = self.load_learn_summary_info()
        learn_all_info = self.load_learn_all_info()

        if learn_summary_info is not None and len(learn_all_info) > 0:
            print("âœ… [ìºì‹œ] ê¸°ì¡´ í•™ìŠµ ë‚´ìš© ì‚¬ìš©")
            await cl.Message(content="âœ… **ê¸°ì¡´ í•™ìŠµ ë‚´ìš©ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.**").send()
            # âœ¨ conversation_historyë„ ë¡œë“œ
            return {
                "cached_knowledge": learn_summary_info,
                "conversation_history": learn_all_info
            }

        # ìºì‹œ ì—†ìŒ â†’ ìµœì´ˆ í•™ìŠµ
        print("ğŸ”„ [í•™ìŠµ] ìºì‹œ ì—†ìŒ - í”„ë¡œì íŠ¸ ìµœì´ˆ í•™ìŠµ ì‹œì‘")
        await cl.Message(content="**ğŸ”„ í”„ë¡œì íŠ¸ ìµœì´ˆ í•™ìŠµ ì‹œì‘...**").send()

        try:
            # additional_query ì—†ì´ í˜¸ì¶œ (ìµœì´ˆ í•™ìŠµ)
            learned_knowledge, conversation_history = await self.learn_project_structure()
            return {"cached_knowledge": learned_knowledge,
                    "conversation_history": conversation_history}
        except Exception as e:
            error_msg = f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\nLM Studio ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš” (http://127.0.0.1:1234)"
            print(error_msg)
            await cl.Message(content=error_msg).send()
            return {
                "cached_knowledge": "",
                "conversation_history": [],
                "error": str(e)
            }
    
    async def additional_learn_project_node(self, state: GraphState) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ì¶”ê°€ í•™ìŠµ ë…¸ë“œ - ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì¶”ê°€ í•™ìŠµ"""
        print("âœ… current node : additional_learn_project_node")

        user_feedback = state.get("user_feedback", "")
        missing_knowledge = state.get("missing_knowledge", "")

        # ë””ë²„ê¹…
        print(f"ğŸ” [additional_learn_project_node] user_feedback: '{user_feedback}' (type: {type(user_feedback)})")

        # í”¼ë“œë°±ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ë¡œ ì§„í–‰ (ì´ ë…¸ë“œì— ì˜¬ ì¼ì´ ì—†ì–´ì•¼ í•¨)
        if not user_feedback or user_feedback.strip() == "":
            print("âš ï¸ [ê²½ê³ ] additional_learn_project_nodeì— í”¼ë“œë°± ì—†ì´ ë„ì°© - ê¸°ì¡´ ìºì‹œ ë°˜í™˜")
            cached_knowledge = self.load_learn_summary_info()
            return {"cached_knowledge": cached_knowledge}

        # ì¶”ê°€ í•™ìŠµ ìˆ˜í–‰
        print("ğŸ”„ [ì¶”ê°€ í•™ìŠµ] - í”„ë¡œì íŠ¸ ì¶”ê°€ í•™ìŠµ ì‹œì‘")
        await cl.Message(content="**ğŸ”„ í”„ë¡œì íŠ¸ ì¶”ê°€ í•™ìŠµ ì‹œì‘...**").send()

        # âœ¨ conversation_historyë¥¼ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ (GraphStateê°€ ì•„ë‹Œ!)
        # ì´ìœ : í”„ë¡œê·¸ë¨ ì¬ì‹œì‘ ë˜ëŠ” ì¤‘ê°„ ì§„ì… ì‹œ GraphStateì— ì—†ì„ ìˆ˜ ìˆìŒ
        conversation_history = self.load_learn_all_info()

        if not conversation_history:
            print("âš ï¸ [ê²½ê³ ] conversation_history ì—†ìŒ - ì¦ë¶„ í•™ìŠµ ë¶ˆê°€, ê¸°ì¡´ ìºì‹œ ë°˜í™˜")
            cached_knowledge = self.load_learn_summary_info()
            return {"cached_knowledge": cached_knowledge}

        # âœ¨ conversation_history ì „ë‹¬
        learned_knowledge = await self.learn_additional_content(
            additional_query=missing_knowledge,
            conversation_history=conversation_history  # âœ¨ íŒŒì¼ì—ì„œ ë¡œë“œí•œ ì´ë ¥ ì „ë‹¬
        )
        self.save_learn_summary_info(learned_knowledge)

        return {"cached_knowledge": learned_knowledge}

    # 2. ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ (ë…¸ë“œ ì•„ë‹˜)
    #í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì „ìš© ì¡°ê±´ë¶€ ì—£ì§€ ë…¸ë“œ
    def testcase_decide_to_retry(self, state: GraphState) -> str:
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
        test_cases = state.get("test_case_info", [])
        if not test_cases:
            return "retry_query"
        else:
            return "continue_workflow"
    

    #ìë™í™”ì½”ë“œ í•¨ìˆ˜ ì „ìš© ì¡°ê±´ë¶€ ì—£ì§€ ë…¸ë“œ
    def automation_function_decide_to_retry(self, state: GraphState) -> str:
        """ìë™í™”ì½”ë“œ í•¨ìˆ˜ ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
        print("âœ… current node : automation_function_decide_to_retry")
        code_snippets = state.get("retrieved_code_snippets", [])
        if not code_snippets:
            return "retry_automation_function"
        else:
            return "generate_code"
        
    #ìë™í™”ì½”ë“œ í•¨ìˆ˜ ì „ìš© ì¡°ê±´ë¶€ ì—£ì§€ ë…¸ë“œ
    def retry_learn_project(self, state: GraphState) -> str:
        """ì‚¬ìš©ì í”¼ë“œë°±ì— ë”°ë¼ ì¶”ê°€ í•™ìŠµ ë˜ëŠ” ì½”ë“œ ìƒì„± ê²°ì •"""
        print("âœ… current node : retry_learn_project")
        user_feedback = state.get("user_feedback", "")

        # ë””ë²„ê¹…
        print(f"ğŸ” [retry_learn_project] user_feedback: '{user_feedback}' (type: {type(user_feedback)})")

        # ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ Noneì´ë©´ ì½”ë“œ ìƒì„±ìœ¼ë¡œ
        if not user_feedback or user_feedback.strip() == "":
            print("ğŸ” [retry_learn_project] â†’ generate_code (ê¸°ì¡´ ì§€ì‹ ì‚¬ìš©)")
            return "generate_code"
        else:
            print("ğŸ” [retry_learn_project] â†’ additional_learn (ì¶”ê°€ í•™ìŠµ)")
            return "additional_learn"
    
    
    # 3. ê·¸ë˜í”„ ë¹Œë“œ ë©”ì„œë“œ
    def _build_graph(self):
        workflow = StateGraph(GraphState)

        # ëª¨ë“  ë…¸ë“œë“¤ ì¶”ê°€
        workflow.add_node("learn_project", self.learn_project_node)
        workflow.add_node("retrieve_test_case", self.testcase_rag_node)
        workflow.add_node("analyze_testcase", self.analyze_testcase_node)
        workflow.add_node("compare_knowledge", self.compare_knowledge_node)
        workflow.add_node("generate_automation_code", self.generate_code_rag_node)
        workflow.add_node("additional_learn_project", self.additional_learn_project_node)

        # ì§„ì…í•˜ëŠ” ë…¸ë“œ ì§€ì •
        workflow.set_entry_point("learn_project")

        # ê·¸ë˜í”„ í”Œë¡œìš°:
        # 0. í•™ìŠµ ë°ì´í„° ìƒì„± (ì—†ìœ¼ë©´ í†µê³¼)
        workflow.add_edge("learn_project", "retrieve_test_case")
        # 1. í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰
        workflow.add_edge("retrieve_test_case", "analyze_testcase")
        # 2. í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¶„ì„
        workflow.add_edge("analyze_testcase", "compare_knowledge")
        # âœ¨ 3. ì§€ì‹ ë¹„êµ â†’ ì‚¬ìš©ì ë²„íŠ¼ ì„ íƒ â†’ ë°”ë¡œ ë¶„ê¸°
        workflow.add_conditional_edges(
            "compare_knowledge",
            self.retry_learn_project,  # ì¡°ê±´ í•¨ìˆ˜ (ìˆ˜ì • ë¶ˆí•„ìš”)
            {
                "additional_learn": "additional_learn_project",  # missing_knowledgeë¡œ ì¦ë¶„ í•™ìŠµ
                "generate_code": "generate_automation_code"      # ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ì½”ë“œ ìƒì„±
            }
        )
        workflow.add_edge("additional_learn_project", "compare_knowledge")
        # 5. ì½”ë“œ ìƒì„± (ì¬í•™ìŠµ + ì½”ë“œ ìƒì„±)
        workflow.add_edge("generate_automation_code", END)

        return workflow.compile()
    
    # run_graph ë©”ì„œë“œë¥¼ ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ë³€ê²½
    async def run_graph(self, query: str) -> GraphState:
        print("ğŸš€ LangGraph ì‹¤í–‰ ì‹œì‘")

        # âœ¨ ì¿¼ë¦¬ íŒŒì‹±: step_indexê°€ ëª…ì‹œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        import re
        issue_key_match = re.search(r'(COMMONR-\d+)', query)
        step_index_match = re.search(r'ìŠ¤í…\s*(\d+)', query)

        if not issue_key_match:
            print(f"âš ï¸ ì¿¼ë¦¬ì—ì„œ issue_keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {query}")
            return []

        issue_key = issue_key_match.group(1)
        specific_step = step_index_match.group(1) if step_index_match else None

        if specific_step:
            print(f"ğŸ¯ íŠ¹ì • ìŠ¤í…ë§Œ ìƒì„±: {issue_key} ìŠ¤í… {specific_step}ë²ˆ")
        else:
            print(f"ğŸ“š ëª¨ë“  ìŠ¤í… ìƒì„±: {issue_key}")

        # ChromaDBì—ì„œ ì§ì ‘ ê²€ìƒ‰
        if specific_step:
            # íŠ¹ì • ìŠ¤í…ë§Œ ê²€ìƒ‰
            where_filter = {
                "$and": [
                    {"issue_key": {"$eq": issue_key}},
                    {"step_index": {"$eq": specific_step}}
                ]
            }
        else:
            # ëª¨ë“  ìŠ¤í… ê²€ìƒ‰
            where_filter = {"issue_key": {"$eq": issue_key}}

        collection = self.testcase_vectorstore.get(where=where_filter)

        if not collection or not collection.get('ids'):
            print(f"âš ï¸ {query}ì— í•´ë‹¹í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
        testcase_results = []
        ids = collection.get('ids', [])
        metadatas = collection.get('metadatas', [])

        for i in range(len(ids)):
                    metadata = metadatas[i] if i < len(metadatas) else {}
                    issue_key_meta = metadata.get('issue_key', query)
                    step_index_meta = metadata.get('step_index', i+1)

                    # ê° ìŠ¤í…ì— ëŒ€í•œ ì¿¼ë¦¬ ìƒì„±
                    step_query = f"{issue_key_meta}ì˜ ìŠ¤í… {step_index_meta}ë²ˆ"

                    testcase_results.append({
                        "query": step_query,  # ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ ì¶”ê°€
                        "metadata": metadata,
                    })

        # step_indexë¡œ ì •ë ¬
        testcase_results.sort(key=lambda x: int(x['metadata'].get('step_index', 0)))
        
        for i in testcase_results :
            query = i['query']
            metadata = i['metadata']

            # ë©”íƒ€ë°ì´í„°ì—ì„œ issue_keyì™€ step_index ì¶”ì¶œ
            issue_key = metadata.get('issue_key', 'UNKNOWN')
            step_index = metadata.get('step_index', '0')

            # COMMONR-21 â†’ 21 ì¶”ì¶œ
            import re
            match = re.search(r'COMMONR-(\d+)', issue_key)
            issue_number = match.group(1) if match else 'UNKNOWN'

            initial_state = {
            "original_query": query
            }
            # invoke ëŒ€ì‹  ainvoke ì‚¬ìš©
            final_state = await self.graph.ainvoke(initial_state)
            
            output_dir = "/home/bes/BES_QE_SDK/generated_codes"
            #í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(output_dir, exist_ok=True)
            # íŒŒì¼ëª… ìƒì„±: testCOMMONR21_1.py
            output_file = os.path.join(output_dir, f"testCOMMONR_{issue_number}_{step_index}.py")
            
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```python, ```) ì œê±°
            cleaned_code = re.sub(r'^```python\s*\n|^```\s*\n|\n```\s*$', '', final_state['final_code'], flags=re.MULTILINE).strip()
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(cleaned_code)
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_file}")
            
        
        print("âœ… LangGraph ì‹¤í–‰ ì™„ë£Œ")
        return final_state
        
async def process_query(user_query):
    """
    ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë°›ì•„ RAG_Graphë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    graph_run = RAG_Graph(
        testcase_db_path="/home/bes/BES_QE_RAG/testcase_rag/testcase_vectordb",
        automation_db_path="/home/bes/BES_QE_RAG/automation_rag/automation_vectordb",
        testcase_collection_name="testcase_vectordb",
        automation_collection_name="test_automation_functions",
        testcase_embedding_model="intfloat/multilingual-e5-large",
        automation_embedding_model="BAAI/bge-m3",
        lm_studio_url="http://127.0.0.1:1234/v1",
        lm_studio_model="qwen/qwen3-coder-30b"
    )

    final_state = await graph_run.run_graph(user_query)
    
    return final_state
    
