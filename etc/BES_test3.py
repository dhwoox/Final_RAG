from langgraph.graph import StateGraph, END
import chromadb
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.language_models.llms import LLM
from langchain_core.callbacks.manager import CallbackManagerForLLMRun

# 6. typing ë° pathlib (ë³€ê²½ ì—†ìŒ)
from typing import List, Dict, Any, Optional, Tuple, TypedDict, Annotated
from pathlib import Path
import json
import requests
import warnings
import datetime
import os
import re
import chainlit as cl

# FutureWarning ë¬´ì‹œ
warnings.filterwarnings("ignore", category=FutureWarning)

class GraphState(TypedDict, total=False):
    original_query: str                     # ì‚¬ìš©ìì˜ ìµœì´ˆ ì§ˆë¬¸
    test_case_info: List[Dict[str, Any]]    # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ RAGì—ì„œ ì°¾ì€ ì •ë³´

    # ë¦¬ì†ŒìŠ¤ íƒìƒ‰ ê²°ê³¼
    resource_plan_text: str
    resource_plan: Dict[str, Any]

    # Phase 2: ê¸°ë³¸ êµ¬ì¡° ìƒì„± ê²°ê³¼
    base_structure: str                     # í•µì‹¬ 3íŒŒì¼ ê¸°ë°˜ ê¸°ë³¸ í´ë˜ìŠ¤ êµ¬ì¡°
    core_files_loaded: bool                 # í•µì‹¬ íŒŒì¼ ë¡œë“œ ì™„ë£Œ ì—¬ë¶€

    # Phase 3: ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì½”ë“œ
    category_codes: Dict[str, Any]          # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì½”ë“œ ë”•ì…”ë„ˆë¦¬

    # Phase 4: í†µí•© ë° ê²€ì¦ ê²°ê³¼
    final_code: str                         # ìµœì¢… í†µí•©ëœ ì½”ë“œ
    coverage: int                           # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì»¤ë²„ë¦¬ì§€ (%)
    validation_result: Dict[str, Any]       # ê²€ì¦ ê²°ê³¼ ìƒì„¸
    needs_refinement: bool                  # ì¬ìƒì„± í•„ìš” ì—¬ë¶€

    # ì½”ë“œ ìƒì„± ê²°ê³¼ (ìµœì¢…)
    generated_plan: str
    generated_code: str
    artifact_info: Dict[str, str]
    file_path: str

    # ì˜¤ë¥˜
    error: str


class LMStudioLLM(LLM):
    """LM Studioì™€ ì—°ë™í•˜ëŠ” LangChain í˜¸í™˜ LLM í´ë˜ìŠ¤"""
    
    base_url: str = "http://127.0.0.1:1234/v1"
    model_name: str = "qwen/qwen3-8b"
    temperature: float = 0.1
    max_tokens: int = 8192  # ìë™í™” ì½”ë“œ ìƒì„±ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
    
    def __init__(self, 
                 base_url: str = "http://127.0.0.1:1234/v1",
                 model_name: str = "qwen/qwen3-8b",
                 temperature: float = 0.1,
                 max_tokens: int = 8192,
                 **kwargs):
        super().__init__(**kwargs)
        self.base_url = base_url.rstrip('/')
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self._test_connection()
    
    def _test_connection(self):
        """LM Studio ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(f"{self.base_url}/models", timeout=5)
            if response.status_code == 200:
                models = response.json()
                print(f"âœ… LM Studio ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(models.get('data', []))}ê°œ")
            else:
                print(f"âš ï¸ LM Studio ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”: {response.status_code}")
        except Exception as e:
            print(f"âŒ LM Studio ì—°ê²° ì‹¤íŒ¨: {e}")
    
    @property
    def _llm_type(self) -> str:
        return "lm_studio"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        try:
            payload = {
                "model": self.model_name,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "stream": False
            }

            if stop:
                payload["stop"] = stop

            response = requests.post(
                f"{self.base_url}/chat/completions",
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=10000000  # 1000ì´ˆ (16ë¶„ 40ì´ˆ)ë¡œ ì„¤ì •
            )

            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                error_detail = response.text[:500]  # ì—ëŸ¬ ìƒì„¸ ì •ë³´
                print(f"âŒ LM Studio 400 ì—ëŸ¬ ìƒì„¸:\n{error_detail}")
                return f"Error: LM Studio ì‘ë‹µ ì˜¤ë¥˜ (status: {response.status_code})\nìƒì„¸: {error_detail}"

        except Exception as e:
            return f"Error: LM Studio í†µì‹  ì˜¤ë¥˜ - {str(e)}"

class RAG_Pipeline :
    """
    Vector DB, Embedding Model, LM Studioë¥¼ ì—°ê²°í•˜ì—¬ RAGë¥¼ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤.
    """

    def __init__(self,
                testcase_db_path="/Users/admin/Documents/2025_project/QE_RAG_COMPANY/QE_RAG_2025/chroma_db",           # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DB í´ë”
                testcase_collection_name="jira_test_cases",        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì»¬ë ‰ì…˜ëª…
                testcase_embedding_model="intfloat/multilingual-e5-large",        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìš© ì„ë² ë”© ëª¨ë¸
                lm_studio_url: str = "http://127.0.0.1:1234/v1",
                lm_studio_model: str = "qwen/qwen3-8b"
                ):
        
        self.testcase_db_path = testcase_db_path
        self.testcase_collection_name = testcase_collection_name
        self.testcase_embedding_model = testcase_embedding_model
        self.lm_studio_url = lm_studio_url
        self.lm_studio_model = lm_studio_model
        
        self.llm = LMStudioLLM(
            base_url=lm_studio_url,
            model_name=lm_studio_model,
            temperature=0.1,
            max_tokens=8192  # ìë™í™” ì½”ë“œ ìƒì„±ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
        )
    
        # í´ë” ì¡´ì¬ í™•ì¸
        self._check_db_directories()
        
        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìš© ì„ë² ë”© ëª¨ë¸ ì„¤ì • (GPU ì‚¬ìš©)
        print(f"ğŸ”§ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ìš© ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {testcase_embedding_model}")
        testcase_model_kwargs = {'device': 'cpu', 'trust_remote_code': True}
        testcase_encode_kwargs = {'normalize_embeddings': True, 'batch_size': 4}
        
        self.testcase_embeddings = HuggingFaceEmbeddings(
            model_name=testcase_embedding_model,
            model_kwargs=testcase_model_kwargs,
            encode_kwargs=testcase_encode_kwargs
        )
        print(f"âœ… í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # 2ê°œì˜ ë²¡í„° ì €ì¥ì†Œ ì—°ê²° (ê°ê° ë‹¤ë¥¸ í´ë”ì™€ ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸)
        self.testcase_vectorstore = self._connect_to_chroma(
            self.testcase_db_path, 
            self.testcase_collection_name, 
            self.testcase_embeddings,
            "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤",
            testcase_embedding_model
        )

        # âœ¨ NEW: gsdk_rag_context ë¡œë”©
        print("\nğŸ“š gsdk_rag_context ì‹œìŠ¤í…œ ë¡œë”© ì¤‘...")
        self._load_gsdk_context()


    def _check_db_directories(self):
        """DB ë””ë ‰í„°ë¦¬ ì¡´ì¬ í™•ì¸"""
        print("ğŸ“ ChromaDB ë””ë ‰í„°ë¦¬ í™•ì¸ ì¤‘...")
        
        if not os.path.exists(self.testcase_db_path):
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DB ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.testcase_db_path}")
            print(f"   ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
        else:
            print(f"âœ… í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DB ë””ë ‰í„°ë¦¬ í™•ì¸: {self.testcase_db_path}")
        
    
    def _connect_to_chroma(self, persist_directory: str, collection_name: str, 
                          embedding_function, db_type: str, embedding_model_name: str) -> Chroma:
        """ê°œë³„ ChromaDB í´ë”ì˜ ì»¬ë ‰ì…˜ì— íŠ¹ì • ì„ë² ë”© ëª¨ë¸ë¡œ ì—°ê²°"""
        try:
            vectorstore = Chroma(
                collection_name=collection_name,
                embedding_function=embedding_function,
                persist_directory=persist_directory  # ê°ê° ë‹¤ë¥¸ ê²½ë¡œ ì‚¬ìš©
            )
            print(f"âœ… ChromaDB '{persist_directory}/{collection_name}' ({db_type}) ì—°ê²° ì™„ë£Œ")
            print(f"   ğŸ§  ì„ë² ë”© ëª¨ë¸: {embedding_model_name}")
            
            # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
            try:
                collection = vectorstore.get()
                doc_count = len(collection.get('ids', []))
                print(f"   ğŸ“Š {db_type} ë¬¸ì„œ ìˆ˜: {doc_count}ê°œ")
            except Exception as e:
                print(f"   â„¹ï¸ ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸ ë¶ˆê°€: {e}")
            
            return vectorstore
        except Exception as e:
            print(f"âŒ ChromaDB '{persist_directory}' ì—°ê²° ì‹¤íŒ¨: {e}")
            raise


    def _load_gsdk_context(self):
        """
        gsdk_rag_context ì‹œìŠ¤í…œ ë¡œë”©
        - README.md: ììœ¨ì  íƒìƒ‰ í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ
        - 3ê°œ ê°€ì´ë“œ ë¬¸ì„œ: WORKFLOW, REFERENCE, TEST_DATA
        - 3ê°œ ë¦¬ì†ŒìŠ¤ JSON: category_map, manager_api_index, event_codes
        """
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ gsdk_rag_context í´ë” ì°¾ê¸°
            current_dir = Path(__file__).parent
            project_root = current_dir.parent
            gsdk_context_dir = project_root / "gsdk_rag_context"

            if not gsdk_context_dir.exists():
                print(f"âš ï¸ gsdk_rag_context í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gsdk_context_dir}")
                print(f"   ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.guides = {}
                self.resources = {}
                return

            # ê°€ì´ë“œ ë¬¸ì„œ ë¡œë“œ
            self.guides = {
                'readme': self._read_file(gsdk_context_dir / "README.md"),
                'workflow': self._read_file(gsdk_context_dir / "01_WORKFLOW_GUIDE.md"),
                'reference': self._read_file(gsdk_context_dir / "02_REFERENCE_GUIDE.md"),
                'test_data': self._read_file(gsdk_context_dir / "03_TEST_DATA_GUIDE.md"),
            }

            # ë¦¬ì†ŒìŠ¤ JSON ë¡œë“œ
            resources_dir = gsdk_context_dir / "resources"
            self.resources = {
                'category_map': self._read_json(resources_dir / "category_map.json"),
                'manager_api': self._read_json(resources_dir / "manager_api_index.json"),
                'event_codes': self._read_json(resources_dir / "event_codes.json"),
            }

            # ë¡œë”© ì„±ê³µ ë©”ì‹œì§€
            print(f"âœ… gsdk_rag_context ë¡œë”© ì™„ë£Œ")
            print(f"   ğŸ“– ê°€ì´ë“œ ë¬¸ì„œ: {len(self.guides)}ê°œ")
            print(f"   ğŸ“¦ ë¦¬ì†ŒìŠ¤ íŒŒì¼: {len(self.resources)}ê°œ")
            print(f"   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬: {len(self.resources.get('category_map', {}).get('categories', []))}ê°œ")

        except Exception as e:
            print(f"âš ï¸ gsdk_rag_context ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"   ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.guides = {}
            self.resources = {}


    def _read_file(self, file_path: Path) -> str:
        """íŒŒì¼ ì½ê¸° í—¬í¼"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            print(f"   âœ“ {file_path.name} ë¡œë“œ ì™„ë£Œ")
            return content
        except Exception as e:
            print(f"   âœ— {file_path.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
            return ""


    def _read_json(self, file_path: Path) -> dict:
        """JSON íŒŒì¼ ì½ê¸° í—¬í¼"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"   âœ“ {file_path.name} ë¡œë“œ ì™„ë£Œ")
            return data
        except Exception as e:
            print(f"   âœ— {file_path.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}


    def _extract_keywords(self, text: str) -> List[str]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        - ì˜ë¬¸ í‚¤ì›Œë“œ (ì†Œë¬¸ì)
        - í•œê¸€ í‚¤ì›Œë“œ (ì›ë³¸)
        """
        # ì˜ë¬¸ í‚¤ì›Œë“œ ì¶”ì¶œ (ì•ŒíŒŒë²³ë§Œ)
        english_keywords = re.findall(r'\b[a-zA-Z]+\b', text.lower())

        # í•œê¸€ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œê¸€ë§Œ)
        korean_keywords = re.findall(r'[ê°€-í£]+', text)

        # ì¤‘ë³µ ì œê±° ë° ê²°í•©
        all_keywords = list(set(english_keywords + korean_keywords))

        return all_keywords

    # ------------------------------------------------------------------
    # ë¦¬ì†ŒìŠ¤ ë„ìš°ë¯¸ (LLMì´ ì„ íƒí•œ í•­ëª©ì„ ì‹¤ë°ì´í„°ë¡œ ë³€í™˜)
    # ------------------------------------------------------------------

    def _get_category_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        if not name or not self.resources.get('category_map'):
            return None

        target = name.strip().lower()
        for cat in self.resources['category_map'].get('categories', []):
            if cat.get('name', '').lower() == target:
                return cat

        # ë¶€ë¶„ ì¼ì¹˜ë„ í—ˆìš©
        for cat in self.resources['category_map'].get('categories', []):
            if target in cat.get('name', '').lower():
                return cat
        return None

    async def resource_planner_node(self, state: GraphState) -> Dict[str, Any]:
        """LLMì—ê²Œ ë¦¬ì†ŒìŠ¤ ì„ íƒì„ ë§¡ê¸°ê³  ê²°ê³¼ë¥¼ ì •ë¦¬"""
        test_case_info = state.get("test_case_info", [])
        if not test_case_info:
            message = "âš ï¸ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ì—†ì–´ ë¦¬ì†ŒìŠ¤ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            await cl.Message(content=message).send()
            return {"resource_plan_text": message, "resource_plan": {}, "selected_resources": {}}

        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ í…ìŠ¤íŠ¸ì™€ í‚¤ì›Œë“œ
        combined_text = "\n\n".join(tc.get("content", "") for tc in test_case_info)
        keywords = self._extract_keywords(combined_text)

        # ğŸ†• ì „ì²´ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ (ìƒ˜í”Œì´ ì•„ë‹Œ ì „ì²´)
        # category_map.json ì „ì²´ (keywords, description, manager_methods í¬í•¨)
        category_map_full = json.dumps(
            self.resources.get("category_map", {}).get("categories", []),
            ensure_ascii=False,
            indent=2
        )

        # manager_api_index.json ì „ì²´ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°)
        manager_api_full = json.dumps(
            self.resources.get("manager_api", {}),
            ensure_ascii=False,
            indent=2
        )

        # event_codes ì „ì²´
        event_codes_full = json.dumps(
            self.resources.get("event_codes", {}).get("commonly_monitored_events", []),
            ensure_ascii=False,
            indent=2
        )

        resource_prompt = (
            f"ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ GSDK ìë™í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ **ê´€ë ¨ëœ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ì„ íƒ**í•˜ì„¸ìš”.\n\n"
            "## ğŸ¯ ì¤‘ìš” ì›ì¹™\n\n"
            "- í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì™€ **ì¡°ê¸ˆì´ë¼ë„ ê´€ë ¨ ìˆëŠ”** ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”\n"
            "- ê° ì¹´í…Œê³ ë¦¬ì˜ keywords, description, manager_methodsë¥¼ ë³´ê³  ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ì„¸ìš”\n"
            "- **ë¶ˆí™•ì‹¤í•˜ë©´ í¬í•¨**í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤ (ë‚˜ì¤‘ì— Phase 2-3ì—ì„œ í•„í„°ë§ë¨)\n"
            "- Manager APIëŠ” í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ manager_methodsë¥¼ **ëª¨ë‘** í¬í•¨í•˜ì„¸ìš”\n"
            "- Event codesëŠ” í…ŒìŠ¤íŠ¸ ê²€ì¦ì— í•„ìš”í•œ ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ í¬í•¨í•˜ì„¸ìš”\n"
            "- ì¶©ë¶„íˆ ë§ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì½”ë“œ ìƒì„± í’ˆì§ˆì„ ë†’ì…ë‹ˆë‹¤\n\n"
            "---\n\n"
            "## ğŸ“‹ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤\n\n"
            "\"\"\"\n"
            f"{combined_text}\n"
            "\"\"\"\n\n"
            f"**ì¶”ì¶œëœ í‚¤ì›Œë“œ**: {', '.join(keywords[:40])}\n\n"
            "---\n\n"
            "## ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ì „ì²´ ì¹´í…Œê³ ë¦¬ ëª©ë¡\n"
            "(ê° ì¹´í…Œê³ ë¦¬ì˜ keywords, description, manager_methodsë¥¼ í™•ì¸í•˜ì—¬ ê´€ë ¨ì„± íŒë‹¨)\n\n"
            "```json\n"
            f"{category_map_full}\n"
            "```\n\n"
            "---\n\n"
            "## ğŸ“‹ Manager API ì¸ë±ìŠ¤ (ì „ì²´)\n\n"
            "```json\n"
            f"{manager_api_full}\n"
            "```\n\n"
            "---\n\n"
            "## ğŸ“‹ ê°ì‹œ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ ëª©ë¡ (ì „ì²´)\n\n"
            "```json\n"
            f"{event_codes_full}\n"
            "```\n\n"
            "---\n\n"
            "## ğŸ¯ ì¶œë ¥ í˜•ì‹\n\n"
            "JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. **ê´€ë ¨ëœ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ì¶©ë¶„íˆ í¬í•¨**í•˜ì„¸ìš”.\n\n"
            "```json\n"
            "{{\n"
            "  \"categories\": [\"user\", \"auth\", \"card\", \"finger\"],\n"
            "  \"manager_methods\": [\"enrollUsers\", \"deleteUser\", \"setAuthConfig\", \"getAuthConfig\", \"verifyUser\"],\n"
            "  \"event_codes\": [\"EVENT_USER_ENROLLED\", \"EVENT_AUTH_SUCCESS\", \"EVENT_VERIFY_SUCCESS\"],\n"
            "  \"resource_files\": [\"demo/example/user/user.py\", \"demo/example/auth/auth.py\"],\n"
            "  \"notes\": \"user: ì‚¬ìš©ì ë“±ë¡/ì‚­ì œ, auth: ì¸ì¦ ì„¤ì •, card/finger: ê²€ì¦ ê´€ë ¨\"\n"
            "}}\n"
            "```\n\n"
            "**ì£¼ì˜**: ì„¤ëª… ë¬¸ì¥ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."
        )

        # ğŸ” ë””ë²„ê¹…: í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¶œë ¥
        prompt_length = len(resource_prompt)
        estimated_tokens = prompt_length // 4
        print(f"\nğŸ” [DEBUG] resource_planner_node í”„ë¡¬í”„íŠ¸ í†µê³„:")
        print(f"   - í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {prompt_length:,} ê¸€ì")
        print(f"   - ì˜ˆìƒ í† í°: ~{estimated_tokens:,} í† í°")
        print(f"   - category_map_full ê¸¸ì´: {len(category_map_full):,} ê¸€ì")
        print(f"   - manager_api_full ê¸¸ì´: {len(manager_api_full):,} ê¸€ì")
        print(f"   - event_codes_full ê¸¸ì´: {len(event_codes_full):,} ê¸€ì")

        plan_text = await self.llm.ainvoke(resource_prompt)
        default_plan = {
            "categories": [],
            "manager_methods": [],
            "event_codes": [],
            "resource_files": [],
            "notes": ""
        }
        parsed_plan = self._safe_parse_json(plan_text, {"resource_plan": default_plan})
        resource_plan = parsed_plan.get("resource_plan", parsed_plan if parsed_plan != {} else default_plan)

        await cl.Message(
            content=f"âœ… **ë¦¬ì†ŒìŠ¤ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ**\n```json\n{json.dumps(resource_plan, ensure_ascii=False, indent=2)}\n```"
        ).send()

        return {
            "resource_plan_text": plan_text,
            "resource_plan": resource_plan
        }



#RAG_Pipeline(RAG ê¸°ë³¸ê°’)ì„ ìƒì†ë°›ì•„ í…ŒìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ í•¨ìˆ˜ë¥¼ ìƒì„±
class RAG_Function(RAG_Pipeline) :
    async def retrieve_test_case(self, query: str) -> List[Dict]:
        try:
            # ì¿¼ë¦¬ì—ì„œ issue_key, step_index, number ì¶”ì¶œ
            # ì˜ˆì‹œ:
            # "COMMONR-30ì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í… 2ë²ˆ" -> issue_key="COMMONR-30", step_index="2", number=None
            # "COMMONR-30ì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í… 1_2ë²ˆ" -> issue_key="COMMONR-30", step_index="1", number="2"
            # "COMMONR-30ì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í… 1ë²ˆì˜ 2ë²ˆ" -> issue_key="COMMONR-30", step_index="1", number="2"

            issue_key_match = re.search(r'(COMMONR-\d+)', query)

            # step_index_number í˜•ì‹ (ì˜ˆ: "ìŠ¤í… 1_2")
            step_number_match = re.search(r'ìŠ¤í…\s*(\d+)_(\d+)', query)
            # step_indexë§Œ (ì˜ˆ: "ìŠ¤í… 1")
            step_index_match = re.search(r'ìŠ¤í…\s*(\d+)', query)
            # "ìŠ¤í… 1ë²ˆì˜ 2ë²ˆ" í˜•ì‹
            step_of_number_match = re.search(r'ìŠ¤í…\s*(\d+).*?(\d+)ë²ˆ', query)

            if not issue_key_match:
                print(f"âš ï¸ ì¿¼ë¦¬ì—ì„œ issue_keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {query}")
                return []

            issue_key = issue_key_match.group(1)
            step_index = None
            number = None

            # number ì¶”ì¶œ ìš°ì„ ìˆœìœ„
            if step_number_match:
                # "ìŠ¤í… 1_2" í˜•ì‹
                step_index = step_number_match.group(1)
                number = step_number_match.group(2)
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key}, step_index={step_index}, number={number}")
            elif step_of_number_match:
                # "ìŠ¤í… 1ë²ˆì˜ 2ë²ˆ" í˜•ì‹
                step_index = step_of_number_match.group(1)
                number = step_of_number_match.group(2)
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key}, step_index={step_index}, number={number}")
            elif step_index_match:
                # "ìŠ¤í… 1" í˜•ì‹ (number ì—†ìŒ)
                step_index = step_index_match.group(1)
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key}, step_index={step_index} (ì „ì²´)")
            else:
                print(f"   ğŸ” ê²€ìƒ‰ ì¡°ê±´: issue_key={issue_key} (ëª¨ë“  ìŠ¤í…)")

            # ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„± (step_indexê¹Œì§€ë§Œ í•„í„°ë§, numberëŠ” ë‚˜ì¤‘ì— LLMì—ê²Œ ì „ë‹¬)
            if step_index:
                where_filter = {
                    "$and": [
                        {"issue_key": {"$eq": issue_key}},
                        {"step_index": {"$eq": step_index}}
                    ]
                }
            else:
                where_filter = {"issue_key": {"$eq": issue_key}}

            # ChromaDBì—ì„œ ì§ì ‘ ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ ê²€ìƒ‰
            collection = self.testcase_vectorstore.get(where=where_filter)

            if not collection or not collection.get('ids'):
                print(f"   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
            testcase_results = []
            ids = collection.get('ids', [])
            documents = collection.get('documents', [])
            metadatas = collection.get('metadatas', [])

            for i in range(len(ids)):
                testcase_results.append({
                    "content": documents[i] if i < len(documents) else "",
                    "metadata": metadatas[i] if i < len(metadatas) else {},
                })

            print(f"   ğŸ“š í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ DBì—ì„œ {len(testcase_results)}ê°œ ê²€ìƒ‰ë¨")
            print(f"ğŸ“Š ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ {len(testcase_results)}ê°œ")
            return testcase_results

        except Exception as e:
            print(f"âŒ ë²¡í„° DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []


    def _safe_parse_json(self, response_text: str, default: dict) -> dict:
        """ì•ˆì „í•œ JSON íŒŒì‹± í—¬í¼"""
        import re
        import json

        try:
            # ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ strì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if hasattr(response_text, 'content'):
                response_text = response_text.content

            response_str = str(response_text)

            # ë””ë²„ê¹…: ì‘ë‹µ ì•ë¶€ë¶„ ì¶œë ¥
            print(f"   ğŸ” [JSON íŒŒì‹±] ì‘ë‹µ ê¸¸ì´: {len(response_str)}ì")
            print(f"   ğŸ” [JSON íŒŒì‹±] ì‘ë‹µ ì• 200ì: {response_str[:200]}")

            # JSON ë¸”ë¡ ì°¾ê¸° - greedy ë°©ì‹ìœ¼ë¡œ ë³€ê²½
            patterns = [
                r'```json\s*(\{.*\})\s*```',  # âœ… .* ëŠ” ìµœëŒ€ ë§¤ì¹­ - ì¤‘ì²©ëœ { } ì²˜ë¦¬ ê°€ëŠ¥
                r'```\s*(\{.*\})\s*```',
                r'(\{.*\})'
            ]

            for i, pattern in enumerate(patterns):
                match = re.search(pattern, response_str, re.DOTALL)
                if match:
                    json_str = match.group(1).strip()
                    try:
                        parsed = json.loads(json_str)
                        print(f"   âœ… [JSON íŒŒì‹±] íŒ¨í„´ {i+1}ë¡œ ì„±ê³µ, extracted_info ê°œìˆ˜: {len(parsed.get('extracted_info', []))}")
                        return parsed
                    except json.JSONDecodeError as je:
                        print(f"   âš ï¸ [JSON íŒŒì‹±] íŒ¨í„´ {i+1} ë§¤ì¹­ë˜ì—ˆìœ¼ë‚˜ íŒŒì‹± ì‹¤íŒ¨: {je}")
                        continue

            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"   âŒ [JSON íŒŒì‹±] ëª¨ë“  íŒ¨í„´ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
            return default

        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return default


    def _read_full_file(self, file_path: str, max_lines: int = None) -> str:
        """
        íŒŒì¼ ì „ì²´ë¥¼ ì½ì–´ ë¬¸ìì—´ë¡œ ë°˜í™˜

        Args:
            file_path: ì½ì„ íŒŒì¼ ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ)
            max_lines: ìµœëŒ€ ë¼ì¸ ìˆ˜ (Noneì´ë©´ ì „ì²´)

        Returns:
            íŒŒì¼ ë‚´ìš© (ë¬¸ìì—´)
        """
        try:
            project_root = Path(__file__).parent.parent
            full_path = project_root / file_path

            if not full_path.exists():
                print(f"   âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                return f"# íŒŒì¼ ì—†ìŒ: {file_path}"

            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                if max_lines:
                    lines = []
                    for idx, line in enumerate(f):
                        if idx >= max_lines:
                            lines.append(f"... (ìƒëµ: {max_lines}ë¼ì¸ ì´ˆê³¼)")
                            break
                        lines.append(line.rstrip('\n'))
                    content = '\n'.join(lines)
                else:
                    content = f.read()

            print(f"   âœ“ {file_path} ë¡œë“œ ì™„ë£Œ ({len(content)} chars)")
            return content

        except Exception as e:
            print(f"   âœ— {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
            return f"# íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path}\n# ì˜¤ë¥˜: {e}"


    def _load_category_files_full(self, category_name: str) -> Dict[str, str]:
        """
        ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ê´€ë ¨ íŒŒì¼ì„ í†µì§¸ë¡œ ë¡œë“œ

        Args:
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (ì˜ˆ: "user", "auth", "finger")

        Returns:
            Dict[íŒŒì¼íƒ€ì…, íŒŒì¼ë‚´ìš©] - {"example": "...", "pb2": "...", "proto": "..."}
        """
        files = {}

        # category_map.jsonì—ì„œ íŒŒì¼ ê²½ë¡œ ì¡°íšŒ
        category_info = self._get_category_by_name(category_name)
        if not category_info:
            print(f"   âš ï¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {category_name}")
            return files

        print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ '{category_name}' íŒŒì¼ ë¡œë“œ ì¤‘...")

        # example íŒŒì¼
        example_file = category_info.get("example_file")
        if example_file:
            files['example'] = self._read_full_file(example_file)

        # pb2 íŒŒì¼
        pb2_file = category_info.get("pb2_file")
        if pb2_file:
            files['pb2'] = self._read_full_file(pb2_file)

        # proto íŒŒì¼
        proto_file = category_info.get("proto_file")
        if proto_file:
            files['proto'] = self._read_full_file(proto_file)

        # pb2_grpc íŒŒì¼ (ì„ íƒì )
        pb2_grpc_file = category_info.get("pb2_grpc_file")
        if pb2_grpc_file:
            files['pb2_grpc'] = self._read_full_file(pb2_grpc_file)

        print(f"   âœ… ì¹´í…Œê³ ë¦¬ '{category_name}' íŒŒì¼ {len(files)}ê°œ ë¡œë“œ ì™„ë£Œ")
        return files


    def _extract_guide_section(self, guide_text: str, section_marker: str) -> str:
        """
        ê°€ì´ë“œ ë¬¸ì„œì—ì„œ íŠ¹ì • ì„¹ì…˜ë§Œ ì¶”ì¶œ

        Args:
            guide_text: ì „ì²´ ê°€ì´ë“œ ë¬¸ì„œ
            section_marker: ì„¹ì…˜ ì‹œì‘ ë§ˆì»¤ (ì˜ˆ: "### 3.1 user ì¹´í…Œê³ ë¦¬")

        Returns:
            í•´ë‹¹ ì„¹ì…˜ ë‚´ìš© (ë‹¤ìŒ ì„¹ì…˜ ì „ê¹Œì§€)
        """
        import re

        if not guide_text or not section_marker:
            return ""

        # section_marker ì´í›„ë¶€í„° ë‹¤ìŒ ### ì „ê¹Œì§€ ì¶”ì¶œ
        pattern = rf"{re.escape(section_marker)}(.*?)(?=\n### |\Z)"
        match = re.search(pattern, guide_text, re.DOTALL | re.MULTILINE)

        if match:
            return match.group(1).strip()

        # ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ìœ ì‚¬ ê²€ìƒ‰
        pattern_loose = rf".*{re.escape(section_marker.split()[-1])}.*\n(.*?)(?=\n### |\Z)"
        match = re.search(pattern_loose, guide_text, re.DOTALL | re.MULTILINE)

        if match:
            return match.group(1).strip()

        return ""


    def _get_relevant_guide_sections(self, guide_type: str, categories: List[str]) -> str:
        """
        ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ê°€ì´ë“œ ì„¹ì…˜ ì¶”ì¶œ

        Args:
            guide_type: 'reference' ë˜ëŠ” 'test_data'
            categories: ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['user', 'auth', 'finger'])

        Returns:
            ê´€ë ¨ ì„¹ì…˜ë“¤ì„ ê²°í•©í•œ ë¬¸ìì—´
        """
        guide_text = self.guides.get(guide_type, '')
        if not guide_text or not categories:
            return ""

        sections = []

        for category_name in categories:
            # REFERENCE_GUIDE ì„¹ì…˜ ì¶”ì¶œ
            if guide_type == 'reference':
                # "### 3.X {category} ì¹´í…Œê³ ë¦¬" í˜•ì‹ ê²€ìƒ‰
                section = self._extract_guide_section(
                    guide_text,
                    f"ì¹´í…Œê³ ë¦¬"
                )
                if section and category_name in section.lower():
                    sections.append(f"## {category_name.upper()} ì¹´í…Œê³ ë¦¬\n\n{section}")

            # TEST_DATA_GUIDE ì„¹ì…˜ ì¶”ì¶œ
            elif guide_type == 'test_data':
                # **Category**: `{category}` í˜•ì‹ ê²€ìƒ‰
                lines = guide_text.split('\n')
                in_section = False
                category_section = []

                for i, line in enumerate(lines):
                    if f'**Category**: `{category_name}`' in line:
                        in_section = True
                        category_section = [line]
                    elif in_section:
                        if line.startswith('**Category**:') and category_name not in line:
                            break
                        category_section.append(line)
                        if i >= len(lines) - 1:
                            break

                if category_section:
                    sections.append(f"## {category_name.upper()} ë°ì´í„° íŒ¨í„´\n\n" + '\n'.join(category_section))

        if not sections:
            # ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê°€ì´ë“œ ì „ì²´ì˜ ì¼ë¶€ ë°˜í™˜
            return guide_text[:5000] + "\n... (ìƒëµ)"

        return "\n\n---\n\n".join(sections)


    def _extract_category_patterns(self, test_data_guide: str, category_name: str) -> str:
        """
        TEST_DATA_GUIDEì—ì„œ íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„° ìƒì„± íŒ¨í„´ ì¶”ì¶œ

        Args:
            test_data_guide: TEST_DATA_GUIDE ì „ì²´ í…ìŠ¤íŠ¸
            category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (ì˜ˆ: 'user', 'auth')

        Returns:
            í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ê´€ë ¨ íŒ¨í„´ ì„¹ì…˜
        """
        if not test_data_guide:
            return ""

        # "**Category**: `{category}`" ë˜ëŠ” ì„¹ì…˜ ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
        lines = test_data_guide.split('\n')
        patterns = []
        in_relevant_section = False
        section_lines = []

        for i, line in enumerate(lines):
            # ì¹´í…Œê³ ë¦¬ íƒœê·¸ ë°œê²¬
            if f'**Category**: `{category_name}`' in line or f'`{category_name}`' in line.lower():
                in_relevant_section = True
                section_lines = [line]
            elif in_relevant_section:
                # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ (##ë¡œ ì‹œì‘) ë˜ëŠ” ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ ë°œê²¬
                if line.startswith('## ') or (line.startswith('**Category**:') and category_name not in line):
                    patterns.append('\n'.join(section_lines))
                    section_lines = []
                    in_relevant_section = False
                else:
                    section_lines.append(line)

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
        if section_lines:
            patterns.append('\n'.join(section_lines))

        if patterns:
            return "\n\n".join(patterns)

        return f"(ì¹´í…Œê³ ë¦¬ '{category_name}'ì— ëŒ€í•œ ë°ì´í„° íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)"



    async def testcase_rag_node(self, state: GraphState) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²€ìƒ‰ ë…¸ë“œ"""
        await cl.Message(content=" **1. ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...**").send()
        query = state['original_query']
        # ìƒì†ë°›ì€ retrieve_test_case ë©”ì„œë“œ í˜¸ì¶œ
        results = await self.retrieve_test_case(query)
        #chainlitì— ì‹¤ì‹œê°„ ê²°ê³¼ê°’ í‘œì‹œ
        await cl.Message(content=f"âœ… **í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ** \n```json\n{json.dumps(results, ensure_ascii=False, indent=2, default=str)}\n```").send()
        return {"test_case_info": results}


    async def base_structure_node(self, state: GraphState) -> Dict[str, Any]:
        """
        Phase 2: í•µì‹¬ 3íŒŒì¼(manager.py, testCOMMONR.py, util.py)ì„ í†µì§¸ë¡œ ë„£ê³ 
        í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìƒì„±
        """
        print("\n" + "="*80)
        print("ğŸ—ï¸ Phase 2: ê¸°ë³¸ êµ¬ì¡° ìƒì„± (í•µì‹¬ 3íŒŒì¼ í†µì§¸ë¡œ)")
        print("="*80)

        test_case_info = state.get("test_case_info", [])
        resource_plan = state.get("resource_plan", {})

        if not test_case_info:
            error_msg = "âš ï¸ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ì—†ì–´ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            await cl.Message(content=error_msg).send()
            return {"base_structure": "", "core_files_loaded": False, "error": error_msg}

        await cl.Message(content="ğŸ—ï¸ **Phase 2: ê¸°ë³¸ êµ¬ì¡° ìƒì„± ì¤‘...**\n- manager.py, testCOMMONR.py, util.py ë¡œë”©\n- í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ê³¨ê²© ìƒì„±").send()

        # í•µì‹¬ 3íŒŒì¼ í†µì§¸ë¡œ ë¡œë“œ
        print("\nğŸ“š í•µì‹¬ 3íŒŒì¼ ë¡œë”© ì¤‘...")
        manager_full = self._read_full_file("demo/demo/manager.py")
        testCOMMONR_full = self._read_full_file("demo/demo/test/testCOMMONR.py")
        util_full = self._read_full_file("demo/demo/test/util.py")

        # ê°€ì´ë“œ ë¬¸ì„œ
        workflow_guide = self.guides.get('workflow', '')

        # ğŸ†• ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê´€ë ¨ ê°€ì´ë“œ ì„¹ì…˜ ì¶”ì¶œ
        categories = resource_plan.get('categories', [])
        reference_sections = self._get_relevant_guide_sections('reference', categories)
        test_data_sections = self._get_relevant_guide_sections('test_data', categories)

        # ğŸ†• Manager API ì¸ë±ìŠ¤ (í•¨ìˆ˜ ê²€ì¦ìš©)
        manager_api_index = json.dumps(
            self.resources.get('manager_api', {}),
            ensure_ascii=False,
            indent=2
        )

        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë‚´ìš© êµ¬ì„±
        test_case_bundle = "\n\n".join([
            f"### í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ #{i+1}\n"
            f"ë‚´ìš©:\n{tc.get('content', '')}\n\n"
            f"ë©”íƒ€ë°ì´í„°:\n```json\n{json.dumps(tc.get('metadata', {}), ensure_ascii=False, indent=2)}\n```"
            for i, tc in enumerate(test_case_info)
        ])

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""# G-SDK í…ŒìŠ¤íŠ¸ ìë™í™” ì½”ë“œ ìƒì„± - Phase 2: ê¸°ë³¸ êµ¬ì¡°

ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ GSDK Python í…ŒìŠ¤íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ **í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ì˜ ê¸°ë³¸ êµ¬ì¡°**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

---

## ğŸ“‹ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤

{test_case_bundle}

---

## ğŸ¯ ë¦¬ì†ŒìŠ¤ ê³„íš

```json
{json.dumps(resource_plan, ensure_ascii=False, indent=2)}
```

---

## ğŸ“š ì°¸ì¡° ì½”ë“œ (í†µì§¸ë¡œ ì œê³µ - ì‹¤ì œ ë©”ì„œë“œë§Œ ì‚¬ìš©í•  ê²ƒ)

### manager.py (ì „ì²´)
```python
{manager_full}
```

### testCOMMONR.py (ì „ì²´)
```python
{testCOMMONR_full}
```

### util.py (ì „ì²´)
```python
{util_full}
```

---

## ğŸ“– WORKFLOW ê°€ì´ë“œ (ì‘ì—… íë¦„)

{workflow_guide}

---

## ğŸ“– REFERENCE ê°€ì´ë“œ (API ë ˆí¼ëŸ°ìŠ¤ - ê´€ë ¨ ì¹´í…Œê³ ë¦¬)

{reference_sections}

---

## ğŸ“– TEST_DATA ê°€ì´ë“œ (ë°ì´í„° ìƒì„± íŒ¨í„´ - ê´€ë ¨ ì¹´í…Œê³ ë¦¬)

{test_data_sections}

---

## ğŸ“‹ Manager API ì¸ë±ìŠ¤ (í•¨ìˆ˜ ê²€ì¦ìš©)

```json
{manager_api_index}
```

---

## ğŸ¯ ìƒì„±í•  ê²ƒ

1. **Import ë¬¸**
   - í•„ìš”í•œ pb2 ëª¨ë“ˆ (resource_planì˜ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
   - manager, util, testCOMMONR
   - unittest, time, random, os, json ë“±

2. **í´ë˜ìŠ¤ ì •ì˜**
   - TestCOMMONR ìƒì†
   - Docstring (í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…)

3. **setUp/tearDown**
   - super().setUp(), super().tearDown() í˜¸ì¶œ
   - ì¶”ê°€ ë°±ì—…/ë³µì›ì´ í•„ìš”í•œ ê²½ìš°ë§Œ ì‘ì„±

4. **í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ ê³¨ê²©**
   - ê° í…ŒìŠ¤íŠ¸ ìŠ¤í…ë³„ TODO ì£¼ì„
   - ë©”ì„œë“œ ì´ë¦„: testCommonr_{{ë²ˆí˜¸}}_{{ì„œë¸Œë²ˆí˜¸}}_{{ê¸°ëŠ¥ëª…}}

5. **ê¸°ë³¸ ì½”ë“œ ë¼ˆëŒ€**
   - ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ íŒ¨í„´ (JSON â†’ UserInfo)
   - ë””ë°”ì´ìŠ¤ ëŠ¥ë ¥ ê²€ì¦ (skipTest ì‚¬ìš©)

## âš ï¸ ì¤‘ìš” ì œì•½ì‚¬í•­

1. **ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë©”ì„œë“œë§Œ ì‚¬ìš©**:
   - manager.py, testCOMMONR.py, util.pyì— ì‹¤ì œë¡œ ì •ì˜ëœ í•¨ìˆ˜ë§Œ ì‚¬ìš©
   - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í—¬í¼ ë©”ì„œë“œëŠ” ì ˆëŒ€ ë§Œë“¤ì§€ ë§ ê²ƒ

2. **ì •í™•í•œ ì‹œê·¸ë‹ˆì²˜ ì‚¬ìš©**:
   - EventMonitor(svcManager, masterID, eventCode=0x..., userID=...)
   - randomNumericUserID(), generateRandomPIN()
   - self.svcManager.enrollUsers(), self.svcManager.getAuthConfig() ë“±

3. **Phase 2ì—ì„œëŠ” ê¸°ë³¸ êµ¬ì¡°ë§Œ**:
   - ìƒì„¸ êµ¬í˜„ì€ Phase 3(ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬)ì—ì„œ ì§„í–‰
   - ì§€ê¸ˆì€ í´ë˜ìŠ¤ ë¼ˆëŒ€ + TODO ì£¼ì„ë§Œ

## ì¶œë ¥ í˜•ì‹

ìˆœìˆ˜ Python ì½”ë“œë§Œ ì¶œë ¥ (ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ```python ì—†ì´)
"""

        print("\nâš™ï¸ LLM í˜¸ì¶œ ì¤‘... (ê¸°ë³¸ êµ¬ì¡° ìƒì„±)")
        base_structure = await self.llm.ainvoke(prompt)

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        base_structure = self._clean_generated_code(base_structure)

        print(f"\nâœ… ê¸°ë³¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ ({len(base_structure)} chars)")
        await cl.Message(content="âœ… **ê¸°ë³¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ**\n- Import ë¬¸, í´ë˜ìŠ¤ ì •ì˜, setUp/tearDown, í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ ê³¨ê²© ìƒì„±ë¨").send()

        return {
            "base_structure": base_structure,
            "core_files_loaded": True
        }


    async def category_processor_node(self, state: GraphState) -> Dict[str, Any]:
        """
        Phase 3: ì¹´í…Œê³ ë¦¬ë³„ë¡œ example, pb2, proto íŒŒì¼ì„ í†µì§¸ë¡œ ë„£ê³ 
        ìƒì„¸ ì½”ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±
        """
        print("\n" + "="*80)
        print("ğŸ”§ Phase 3: ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì½”ë“œ ìƒì„±")
        print("="*80)

        resource_plan = state.get("resource_plan", {})
        base_structure = state.get("base_structure", "")
        test_case_info = state.get("test_case_info", [])

        categories = resource_plan.get("categories", [])

        if not categories:
            print("   âš ï¸ ì¹´í…Œê³ ë¦¬ê°€ ì—†ì–´ ìƒì„¸ ì½”ë“œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {"category_codes": {}}

        await cl.Message(content=f"ğŸ”§ **Phase 3: ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì½”ë“œ ìƒì„± ì¤‘...**\n- ì´ {len(categories)}ê°œ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì˜ˆì •").send()

        category_codes = {}

        for idx, category_name in enumerate(categories, 1):
            print(f"\nğŸ“¦ [{idx}/{len(categories)}] ì¹´í…Œê³ ë¦¬ '{category_name}' ì²˜ë¦¬ ì¤‘...")
            await cl.Message(content=f"ğŸ“¦ **[{idx}/{len(categories)}]** ì¹´í…Œê³ ë¦¬ '{category_name}' ë¶„ì„ ì¤‘...").send()

            # ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ í†µì§¸ë¡œ ë¡œë“œ
            category_files = self._load_category_files_full(category_name)

            if not category_files:
                print(f"   âš ï¸ ì¹´í…Œê³ ë¦¬ '{category_name}' íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                continue

            # LLM í˜¸ì¶œí•˜ì—¬ ì¹´í…Œê³ ë¦¬ë³„ ì½”ë“œ ìƒì„±
            category_code = await self._generate_category_code(
                category_name=category_name,
                category_files=category_files,
                base_structure=base_structure,
                test_case_info=test_case_info,
                resource_plan=resource_plan
            )

            category_codes[category_name] = category_code
            await cl.Message(content=f"âœ… ì¹´í…Œê³ ë¦¬ '{category_name}' ì²˜ë¦¬ ì™„ë£Œ").send()

        print(f"\nâœ… ì „ì²´ {len(category_codes)}ê°œ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")
        return {"category_codes": category_codes}


    async def _generate_category_code(
        self,
        category_name: str,
        category_files: Dict[str, str],
        base_structure: str,
        test_case_info: List[Dict],
        resource_plan: Dict
    ) -> Dict[str, Any]:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ìƒì„¸ ì½”ë“œ ìƒì„±
        """
        test_case_bundle = "\n\n".join([
            f"### í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ #{i+1}\n{tc.get('content', '')}"
            for i, tc in enumerate(test_case_info)
        ])

        # ğŸ†• category_map.jsonì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        category_info = self._get_category_by_name(category_name)
        keywords = category_info.get('keywords', []) if category_info else []
        description = category_info.get('description', '') if category_info else ''
        manager_methods = category_info.get('manager_methods', []) if category_info else []

        # ğŸ†• REFERENCE ê°€ì´ë“œì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ ì¶”ì¶œ
        reference_guide = self.guides.get('reference', '')
        reference_section = self._extract_category_patterns(reference_guide, category_name)

        # ğŸ†• TEST_DATA ê°€ì´ë“œì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ì¶”ì¶œ
        test_data_guide = self.guides.get('test_data', '')
        test_data_patterns = self._extract_category_patterns(test_data_guide, category_name)

        prompt = f"""# G-SDK í…ŒìŠ¤íŠ¸ ìë™í™” - Phase 3: {category_name.upper()} ì¹´í…Œê³ ë¦¬ ìƒì„¸ ì½”ë“œ

ë‹¹ì‹ ì€ GSDK {category_name} ì¹´í…Œê³ ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê¸°ë³¸ êµ¬ì¡°ì— **{category_name} ê´€ë ¨ ìƒì„¸ ì½”ë“œ**ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.

---

## ğŸ“‹ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ({category_name} ê´€ë ¨ ë¶€ë¶„)

{test_case_bundle}

---

## ğŸ—ï¸ ê¸°ë³¸ êµ¬ì¡° (Phase 2ì—ì„œ ìƒì„±ë¨)

```python
{base_structure}
... (ìƒëµ)
```

---

## ğŸ“‹ {category_name.upper()} ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„°

**í‚¤ì›Œë“œ**: {', '.join(keywords) if keywords else 'ì—†ìŒ'}
**ì„¤ëª…**: {description if description else 'ì„¤ëª… ì—†ìŒ'}
**Manager ë©”ì„œë“œ**: {', '.join(manager_methods) if manager_methods else 'ì—†ìŒ'}

---

## ğŸ“– REFERENCE ê°€ì´ë“œ ({category_name} ì¹´í…Œê³ ë¦¬ API ì‚¬ìš©ë²•)

{reference_section if reference_section else '# ê´€ë ¨ ì„¹ì…˜ ì—†ìŒ'}

---

## ğŸ“– TEST_DATA ê°€ì´ë“œ ({category_name} ë°ì´í„° ìƒì„± íŒ¨í„´)

{test_data_patterns if test_data_patterns else '# ê´€ë ¨ íŒ¨í„´ ì—†ìŒ'}

---

## ğŸ“š {category_name.upper()} ì¹´í…Œê³ ë¦¬ ì°¸ì¡° íŒŒì¼ (í†µì§¸ë¡œ)

### example/{category_name}/{category_name}.py
```python
{category_files.get('example', '# íŒŒì¼ ì—†ìŒ')}
... (ë„ˆë¬´ ê¸¸ë©´ ìƒëµ)
```

### {category_name}_pb2.py
```python
{category_files.get('pb2', '# íŒŒì¼ ì—†ìŒ')}
... (ë„ˆë¬´ ê¸¸ë©´ ìƒëµ)
```

### {category_name}.proto
```protobuf
{category_files.get('proto', '# íŒŒì¼ ì—†ìŒ')}
---

## ğŸ¯ ìƒì„±í•  ê²ƒ

1. **Import ì¶”ê°€ ì—¬ë¶€**:
   - {category_name}_pb2 importê°€ í•„ìš”í•œì§€ íŒë‹¨
   - í•„ìš”í•˜ë©´ ì¶”ê°€í•  import ë¬¸ ì œì‹œ

2. **{category_name} ê´€ë ¨ ì„¤ì • ì½”ë“œ**:
   - ì˜ˆ: AuthConfig ì„¤ì • (auth), FingerprintConfig ì„¤ì • (finger)

3. **{category_name} ê´€ë ¨ ë°ì´í„° ìƒì„±**:
   - ì˜ˆ: UserInfo ìƒì„± (user), CardData ìƒì„± (card)

4. **{category_name} ê´€ë ¨ API í˜¸ì¶œ**:
   - manager.pyì˜ ë©”ì„œë“œ ì‚¬ìš© (ì˜ˆ: enrollUsers, setAuthConfig)

5. **{category_name} ê´€ë ¨ ê²€ì¦**:
   - assertEqual, assertTrue ë“±

## ì¶œë ¥ í˜•ì‹

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€ (ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì—†ì´):
{{
  "imports": ["import {category_name}_pb2"],
  "setup_code": "# {category_name} ì„¤ì • ì½”ë“œ\\n...",
  "test_code": "# {category_name} í…ŒìŠ¤íŠ¸ ì½”ë“œ\\n...",
  "assertions": "# {category_name} ê²€ì¦ ì½”ë“œ\\n..."
}}
"""

        print(f"   âš™ï¸ LLM í˜¸ì¶œ ì¤‘... (ì¹´í…Œê³ ë¦¬: {category_name})")
        result = await self.llm.ainvoke(prompt)

        # JSON íŒŒì‹±
        parsed = self._safe_parse_json(result, {
            "imports": [],
            "setup_code": "",
            "test_code": "",
            "assertions": ""
        })

        print(f"   âœ“ ì¹´í…Œê³ ë¦¬ '{category_name}' ì½”ë“œ ìƒì„± ì™„ë£Œ")
        return parsed


    async def merge_validate_node(self, state: GraphState) -> Dict[str, Any]:
        """
        Phase 4: Phase 2 ê¸°ë³¸ êµ¬ì¡° + Phase 3 ì¹´í…Œê³ ë¦¬ë³„ ì½”ë“œ â†’ ìµœì¢… í†µí•©
        í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ 100% ì»¤ë²„ë¦¬ì§€ ê²€ì¦
        """
        print("\n" + "="*80)
        print("ğŸ” Phase 4: ì½”ë“œ í†µí•© ë° ê²€ì¦")
        print("="*80)

        base_structure = state.get("base_structure", "")
        category_codes = state.get("category_codes", {})
        test_case_info = state.get("test_case_info", [])

        await cl.Message(content="ğŸ” **Phase 4: ì½”ë“œ í†µí•© ë° ê²€ì¦ ì¤‘...**\n- ê¸°ë³¸ êµ¬ì¡° + ì¹´í…Œê³ ë¦¬ë³„ ì½”ë“œ ë³‘í•©\n- ì»¤ë²„ë¦¬ì§€ ë¶„ì„").send()

        # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë‚´ìš© êµ¬ì„±
        test_case_bundle = "\n\n".join([
            f"### í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ #{i+1}\n{tc.get('content', '')}"
            for i, tc in enumerate(test_case_info)
        ])

        # ì¹´í…Œê³ ë¦¬ë³„ ì½”ë“œ ìš”ì•½
        category_summary = json.dumps(category_codes, ensure_ascii=False, indent=2)

        prompt = f"""# G-SDK í…ŒìŠ¤íŠ¸ ìë™í™” - Phase 4: ìµœì¢… ì½”ë“œ í†µí•©

ë‹¹ì‹ ì€ ì½”ë“œ í†µí•© ë° ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
Phase 2 ê¸°ë³¸ êµ¬ì¡°ì™€ Phase 3 ì¹´í…Œê³ ë¦¬ë³„ ì½”ë“œë¥¼ **ì™„ë²½í•˜ê²Œ ë³‘í•©**í•˜ì„¸ìš”.

---

## ğŸ—ï¸ ê¸°ë³¸ êµ¬ì¡° (Phase 2)

```python
{base_structure}
```

---

## ğŸ”§ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì½”ë“œ (Phase 3)

```json
{category_summary}
```

---

## ğŸ“‹ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ (ì»¤ë²„ë¦¬ì§€ ê²€ì¦ìš©)

{test_case_bundle}

---

## ğŸ“‹ Manager API ì¸ë±ìŠ¤ (í•¨ìˆ˜ ê²€ì¦ìš©)

```json
{json.dumps(self.resources.get('manager_api', {{}}), ensure_ascii=False, indent=2)[:5000]}
```

**ì‚¬ìš©ë²•**: ì½”ë“œì—ì„œ `self.svcManager.XXX()` í˜¸ì¶œ ì‹œ ìœ„ ì¸ë±ìŠ¤ì— í•´ë‹¹ ë©”ì„œë“œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

---

## ğŸ“‹ Event Codes (ì´ë²¤íŠ¸ ê²€ì¦ìš©)

```json
{json.dumps(self.resources.get('event_codes', {{}}), ensure_ascii=False, indent=2)[:3000]}
```

**ì‚¬ìš©ë²•**: EventMonitorì—ì„œ ì‚¬ìš©í•  ì´ë²¤íŠ¸ ì½”ë“œë¥¼ ìœ„ ëª©ë¡ì—ì„œ ì„ íƒí•˜ì„¸ìš”. (ì˜ˆ: BS2_EVENT_VERIFY_SUCCESS = 0x1000)

---

## ğŸ¯ í•  ì¼

1. **Import ë¬¸ í†µí•©**:
   - ê¸°ë³¸ êµ¬ì¡°ì˜ import + ê° ì¹´í…Œê³ ë¦¬ì˜ imports
   - ì¤‘ë³µ ì œê±°

2. **ì½”ë“œ ë³‘í•©**:
   - setUp ë©”ì„œë“œ: ê¸°ë³¸ êµ¬ì¡° + ê° ì¹´í…Œê³ ë¦¬ setup_code
   - í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ: TODO ì£¼ì„ â†’ ì‹¤ì œ êµ¬í˜„ (category test_code)
   - ê²€ì¦ ì½”ë“œ: assertions ì¶”ê°€

3. **ì»¤ë²„ë¦¬ì§€ ê²€ì¦**:
   - ëª¨ë“  í…ŒìŠ¤íŠ¸ ìŠ¤í…ì´ êµ¬í˜„ë˜ì—ˆëŠ”ê°€?
   - ê° ìŠ¤í…ì´ ì˜¬ë°”ë¥¸ APIë¥¼ í˜¸ì¶œí•˜ëŠ”ê°€?
   - EventMonitor ë“± ê²€ì¦ ë¡œì§ì´ ìˆëŠ”ê°€?

4. **í•¨ìˆ˜ ì¡´ì¬ í™•ì¸ (CRITICAL)**:
   - self.svcManager.XXX() â†’ ìœ„ Manager API ì¸ë±ìŠ¤ì— ì¡´ì¬í•˜ëŠ” ë©”ì„œë“œë§Œ ì‚¬ìš©
   - self.setXXXAuthMode() â†’ testCOMMONR.pyì— ì¡´ì¬í•˜ëŠ” í—¬í¼ë§Œ ì‚¬ìš©
   - util.XXX() â†’ util.pyì— ì¡´ì¬í•˜ëŠ” í•¨ìˆ˜ë§Œ ì‚¬ìš©
   - **ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ invalid_functions ë°°ì—´ì— ì¶”ê°€í•˜ê³  needs_refinement=trueë¡œ ì„¤ì •**

5. **ì´ë²¤íŠ¸ ê²€ì¦ í™•ì¸**:
   - EventMonitorë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, eventCodeê°€ ìœ„ Event Codes ëª©ë¡ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
   - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì´ë²¤íŠ¸ ì½”ë“œ ì‚¬ìš© ì‹œ invalid_functionsì— ì¶”ê°€

## ì¶œë ¥ í˜•ì‹

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€:
{{
  "final_code": "ì™„ì„±ëœ Python ì½”ë“œ ì „ì²´",
  "coverage_percentage": 95,
  "missing_steps": ["ìŠ¤í… 3-2: ì–¼êµ´ ì¸ì¦ ê²€ì¦ ëˆ„ë½"],
  "invalid_functions": ["self.setCardAuthMode (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)"],
  "needs_refinement": false,
  "notes": "ì¶”ê°€ ì„¤ëª…..."
}}
"""

        print("\nâš™ï¸ LLM í˜¸ì¶œ ì¤‘... (ì½”ë“œ í†µí•© ë° ê²€ì¦)")
        result = await self.llm.ainvoke(prompt)

        # JSON íŒŒì‹±
        parsed = self._safe_parse_json(result, {
            "final_code": base_structure,
            "coverage_percentage": 0,
            "missing_steps": [],
            "invalid_functions": [],
            "needs_refinement": True,
            "notes": ""
        })

        final_code = parsed.get("final_code", base_structure)
        coverage = parsed.get("coverage_percentage", 0)
        needs_refinement = parsed.get("needs_refinement", False)

        print(f"\nâœ… ì½”ë“œ í†µí•© ì™„ë£Œ (ì»¤ë²„ë¦¬ì§€: {coverage}%)")

        coverage_emoji = "âœ…" if coverage >= 90 else "âš ï¸" if coverage >= 70 else "âŒ"
        await cl.Message(content=f"{coverage_emoji} **ì½”ë“œ í†µí•© ì™„ë£Œ**\n- ì»¤ë²„ë¦¬ì§€: {coverage}%\n- ì¬ìƒì„± í•„ìš”: {'ì˜ˆ' if needs_refinement else 'ì•„ë‹ˆì˜¤'}").send()

        return {
            "final_code": final_code,
            "generated_code": final_code,  # ê¸°ì¡´ í˜¸í™˜ì„±
            "coverage": coverage,
            "validation_result": parsed,
            "needs_refinement": needs_refinement
        }


    async def refine_node(self, state: GraphState) -> Dict[str, Any]:
        """
        Phase 5: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ë¶€ì¡±í•œ ë¶€ë¶„ ì¬ìƒì„±
        """
        print("\n" + "="*80)
        print("ğŸ”„ Phase 5: ì½”ë“œ ì¬ìƒì„± (ê²€ì¦ ì‹¤íŒ¨ í•­ëª© ìˆ˜ì •)")
        print("="*80)

        validation_result = state.get("validation_result", {})
        final_code = state.get("final_code", "")
        test_case_info = state.get("test_case_info", [])

        await cl.Message(content="ğŸ”„ **Phase 5: ì½”ë“œ ì¬ìƒì„± ì¤‘...**\n- ê²€ì¦ ì‹¤íŒ¨ í•­ëª© ìˆ˜ì •").send()

        missing_steps = validation_result.get("missing_steps", [])
        invalid_functions = validation_result.get("invalid_functions", [])

        prompt = f"""# G-SDK í…ŒìŠ¤íŠ¸ ìë™í™” - Phase 5: ì½”ë“œ ì¬ìƒì„±

ì´ì „ ì½”ë“œì— ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ì •í•˜ì„¸ìš”.

---

## ğŸ” ê²€ì¦ ê²°ê³¼

```json
{json.dumps(validation_result, ensure_ascii=False, indent=2)}
```

---

## ğŸ“„ í˜„ì¬ ì½”ë“œ

```python
{final_code}
```

---

## ğŸ¯ ìˆ˜ì • ì‚¬í•­

1. **ëˆ„ë½ëœ ìŠ¤í… ì¶”ê°€**:
{chr(10).join(f'   - {step}' for step in missing_steps) if missing_steps else '   (ì—†ìŒ)'}

2. **ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ êµì²´**:
{chr(10).join(f'   - {func}' for func in invalid_functions) if invalid_functions else '   (ì—†ìŒ)'}

3. **ëŒ€ì²´ ë°©ë²• ì°¾ê¸°**:
   - manager.py, testCOMMONR.py, util.pyì—ì„œ ìœ ì‚¬í•œ í•¨ìˆ˜ ì°¾ê¸°
   - ì§ì ‘ êµ¬í˜„ ê°€ëŠ¥í•œ ê²½ìš° ê°„ë‹¨í•œ ì½”ë“œë¡œ ëŒ€ì²´

## ì¶œë ¥ í˜•ì‹

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€:
{{
  "final_code": "ìˆ˜ì •ëœ ì™„ì „í•œ ì½”ë“œ",
  "coverage_percentage": 100,
  "needs_refinement": false
}}
"""

        print("\nâš™ï¸ LLM í˜¸ì¶œ ì¤‘... (ì½”ë“œ ì¬ìƒì„±)")
        result = await self.llm.ainvoke(prompt)

        parsed = self._safe_parse_json(result, {
            "final_code": final_code,
            "coverage_percentage": state.get("coverage", 0),
            "needs_refinement": False
        })

        refined_code = parsed.get("final_code", final_code)
        coverage = parsed.get("coverage_percentage", 0)

        print(f"\nâœ… ì½”ë“œ ì¬ìƒì„± ì™„ë£Œ (ì»¤ë²„ë¦¬ì§€: {coverage}%)")
        await cl.Message(content=f"âœ… **ì½”ë“œ ì¬ìƒì„± ì™„ë£Œ**\n- ìµœì¢… ì»¤ë²„ë¦¬ì§€: {coverage}%").send()

        return {
            "final_code": refined_code,
            "generated_code": refined_code,
            "coverage": coverage,
            "needs_refinement": False
        }


class RAG_Graph(RAG_Function):
    def __init__(self, **kwargs):
        """
        RAG_Graph ì´ˆê¸°í™”
        ë¶€ëª¨ í´ë˜ìŠ¤(RAG_Function) ì´ˆê¸°í™” í›„ LangGraph ë¹Œë“œ
        """
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™” (VectorDB, LLM ë“±)
        super().__init__(**kwargs)

        # LangGraph ë¹Œë“œ ë° ì´ˆê¸°í™”
        self.graph = self._build_graph()

        print("âœ… RAG_Graph ì´ˆê¸°í™” ì™„ë£Œ (LangGraph ë¹Œë“œ ì™„ë£Œ)")

    def _derive_artifact_info(self, query: str, state: GraphState) -> Dict[str, str]:
        """íŒŒì¼ ì €ì¥ì„ ìœ„í•œ ë©”íƒ€ ì •ë³´ êµ¬ì„±"""
        issue_key = "UNKNOWN"
        step_hint = "all"

        metadata_source = None
        test_case_info = state.get("test_case_info") or []
        if test_case_info:
            metadata_source = test_case_info[0].get("metadata", {})
        else:
            metadata_source = {}

        if metadata_source:
            issue_key = metadata_source.get("issue_key", issue_key)
            step_hint = metadata_source.get("step_index", step_hint)

        if issue_key == "UNKNOWN":
            import re
            match = re.search(r'(COMMONR-\d+)', query)
            if match:
                issue_key = match.group(1)
        if step_hint == "all" and issue_key != "UNKNOWN":
            import re
            match = re.search(r'ìŠ¤í…\s*(\d+)', query)
            if match:
                step_hint = match.group(1)

        return {
            "issue_key": issue_key,
            "step_hint": str(step_hint),
        }

    def _clean_generated_code(self, code: str) -> str:
        """Markdown ì½”ë“œ ë¸”ë¡ì„ ì œê±°í•˜ê³  ì–‘ë ê³µë°± ì •ë¦¬"""
        import re

        cleaned = re.sub(r'^```python\s*\n', '', code.strip(), flags=re.IGNORECASE)
        cleaned = re.sub(r'```$', '', cleaned.strip())
        return cleaned.strip()

    def _persist_generated_code(self, code: str, artifact: Dict[str, str]) -> str:
        """ìƒì„±ëœ ì½”ë“œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê²½ë¡œ ë°˜í™˜"""
        output_dir = Path(__file__).parent.parent / "generated_codes"
        output_dir.mkdir(exist_ok=True)

        issue_key = artifact.get("issue_key", "UNKNOWN")
        issue_number = issue_key.split('-')[-1] if '-' in issue_key else issue_key
        step_hint = artifact.get("step_hint", "all")
        filename = f"testCOMMONR_{issue_number}_{step_hint}.py"
        file_path = output_dir / filename

        cleaned_code = self._clean_generated_code(code)
        with open(file_path, 'w', encoding='utf-8') as file:
            file.write(cleaned_code)

        print(f"âœ… ì½”ë“œ íŒŒì¼ ì €ì¥: {file_path}")
        return str(file_path)

    def _build_graph(self):
        """
        ìƒˆë¡œìš´ Phase êµ¬ì¡°ë¡œ Graph êµ¬ì„±:
        Phase 0: retrieve_test_case
        Phase 1: plan_resources
        Phase 2: generate_base_structure (í•µì‹¬ 3íŒŒì¼ í†µì§¸ë¡œ)
        Phase 3: process_categories (ì¹´í…Œê³ ë¦¬ë³„ ìˆœì°¨ ì²˜ë¦¬)
        Phase 4: merge_and_validate (í†µí•© + ê²€ì¦)
        Phase 5: refine_final (í•„ìš”ì‹œ)
        """
        workflow = StateGraph(GraphState)

        # ëª¨ë“  ë…¸ë“œë“¤ ì¶”ê°€
        workflow.add_node("retrieve_test_case", self.testcase_rag_node)
        workflow.add_node("plan_resources", self.resource_planner_node)

        # ìƒˆë¡œìš´ Phase 2-5 ë…¸ë“œ
        workflow.add_node("generate_base_structure", self.base_structure_node)
        workflow.add_node("process_categories", self.category_processor_node)
        workflow.add_node("merge_and_validate", self.merge_validate_node)
        workflow.add_node("refine_final", self.refine_node)

        # ì§„ì… ë…¸ë“œ ì„¤ì •
        workflow.set_entry_point("retrieve_test_case")

        # ê·¸ë˜í”„ í”Œë¡œìš° (ìˆœì°¨)
        workflow.add_edge("retrieve_test_case", "plan_resources")
        workflow.add_edge("plan_resources", "generate_base_structure")
        workflow.add_edge("generate_base_structure", "process_categories")
        workflow.add_edge("process_categories", "merge_and_validate")

        # ì¡°ê±´ë¶€ ë¶„ê¸°: needs_refinementì— ë”°ë¼
        workflow.add_conditional_edges(
            "merge_and_validate",
            lambda state: "refine" if state.get("needs_refinement", False) else "end",
            {
                "refine": "refine_final",
                "end": END
            }
        )

        workflow.add_edge("refine_final", END)

        return workflow.compile()

    async def run_graph(self, query: str) -> GraphState:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ LangGraphì— ì „ë‹¬í•˜ê³  ì‚°ì¶œë¬¼ì„ ì •ë¦¬"""
        print("ğŸš€ LangGraph ì‹¤í–‰ ì‹œì‘")

        initial_state: GraphState = {
            "original_query": query
        }

        final_state: GraphState = await self.graph.ainvoke(initial_state)

        generated_code = final_state.get("generated_code")
        if generated_code:
            artifact_info = final_state.get("artifact_info") or self._derive_artifact_info(query, final_state)
            final_state["artifact_info"] = artifact_info
            file_path = self._persist_generated_code(generated_code, artifact_info)
            final_state["file_path"] = file_path
        else:
            print("âš ï¸ ìƒì„±ëœ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        print("âœ… LangGraph ì‹¤í–‰ ì™„ë£Œ")
        return final_state


async def process_query(user_query):
    """
    ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ ë°›ì•„ RAG_Graphë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    graph_run = RAG_Graph(
        testcase_db_path="/Users/admin/Documents/2025_project/QE_RAG_COMPANY/QE_RAG_2025/chroma_db",
        testcase_collection_name="jira_test_cases",
        testcase_embedding_model="intfloat/multilingual-e5-large",
        lm_studio_url="http://127.0.0.1:1234/v1",
        lm_studio_model="qwen/qwen3-8b"
    )

    final_state = await graph_run.run_graph(user_query)
    
    return final_state
    
